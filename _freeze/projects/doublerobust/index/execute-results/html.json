{
  "hash": "53609e1bf504eeb0639f422f22be0e5c",
  "result": {
    "markdown": "---\ntitle: \"Doubly Robust Estimators\"\ndescription: \"An Exploration of a Double Robust Estimator for Causal Inference\"\ndate: \"2023-04-17\"\n\ncategories:\n  - Data Science\n  - Statistics\nabout:\n  template: marquee\nexecute:\n  freeze: auto\n  echo: false\n  warning: false\n  message: false\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n### Doubly Robust Estimators\n\nDoubly Robust estimation allows researchers to take advantage of both an outcome model and a model of treatment. If one or both of the models is correct, the doubly robust estimator will produce an accurate estimate of the causal effect. Here I'll focus on doubly robust estimation for a quantitative outcome and a binary treatment. Here is one such estimator:\n\n\n```{=tex}\n\\begin{aligned}\n&\\frac{1}{n}\\sum \\left[ \\hat{y}_1(\\textrm{covariates}_i) + \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)} - \\frac{\\hat{y}_1(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)} \\right] \\\\\n\n-&\\frac{1}{n}\\sum \\left[ \\hat{y}_0(\\textrm{covariates}_i) + \\frac{Y_i(1 - A_i) }{1 - \\hat{e}(\\textrm{covariates}_i)} - \\frac{\\hat{y}_0(\\textrm{covariates}_i)*(1 - A_i)}{1 - \\hat{e}(\\textrm{covariates}_i)} \\right]\n\\end{aligned}\n```\n\nWhere\n\n-   $\\hat{y}_1(\\textrm{covariates}_i)$ are the predicted values for each individual $i$ with treatment $1$.\n\n-   $Y_i$ and $A_i$ are, respectively, the actual outcome and treatment values for each individual.\n\n-   $\\hat{e}(\\textrm{covariates}_i)$ are the predicted propensity scores for each individual $i$.\n\nThe rest of this page will attempt to explain how the doubly robust property works in this estimator.\n\n### Simulation\n\nThis is the causal diagram for our simulated data:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Where Y is the outcome and A is a binary treatment. All relationships are linear.](index_files/figure-html/daggity-1.png){fig-alt='A causal graph with arrows from W, M, Z, and A to the outcome Y; an arrow from W to X; arrows from X, Z, and N to A' width=672}\n:::\n:::\n\n\n### Boring Methods\n\nConsider a naive researcher who, not knowing anything about doubly robust estimators, creates two estimates of average causal effect. The naive researcher uses uses thorough research and input from experts to come up with two models:\n\n1.  The outcome is affected by the treatment, Z, W, and M.\n\n    Y \\~ A + Z + W + M\n\n2.  The treatment an individual is assigned to is affected by X.\n\n    A \\~ X + Z + N\n\nSince we simulated the data we know that they have arrived at the correct model of the outcome, but an incorrect model of the treatment. Using these models the researcher performs linear regression and inverse probability weighting to arrive at two different estimates of average causal effect.\n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: The Researcher's Puzzling Result\n\n|                                            |                  |\n|:-------------------------------------------|:-----------------|\n|Outcome Formula                             |Y ~ A + Z + W + M |\n|Exposure Formula                            |A ~ X             |\n|Causal Effect Estimate from Outcome Model   |1.005946          |\n|Causal Effect Estimate from Treatment Model |1.952361          |\n:::\n:::\n\n\nThe estimates are at odds and they can't tell which of their models is failing. Both models have equivalently tiny p-values, both models are based on strong evidence from experts.\n\n### One Part of The Doubly Robust Estimator\n\nThe researcher then figures out a way to make an ever worse estimator that will use both models.\n\n$$\n\\frac{1}{n}\\sum \\frac{\\hat{y}_1(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)} - \\frac{1}{n}\\sum \\frac{\\hat{y}_0(\\textrm{covariates}_i)*(1- A_i)}{1-\\hat{e}(\\textrm{covariates}_i)}\n$$\n\nBy using both the outcome and treatment models, the researcher has ensured that this estimator will fail if either the model is wrong. Not only will it fail, but it will fail by the same amount as the individual estimators. This is very important.\n\n### With IPW\n\nFor simplicity let's say IPW is\n\n$$\n\\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)}  - \\frac{1}{n}\\sum \\frac{Y_i (1-A_i)}{1-\\hat{e}(\\textrm{covariates}_i)}\n$$\n\nWhere $Y_i$ are the actual outcome values. If the treatment model is correct this will produce a correct estimate of average causal effect.\n\nFocus just on one side of the equation, and subtract the same side from the bad estimator above:\n\n$$\n\\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)} - \\frac{\\hat{y}_1(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)}\n$$\n\nOur researcher, sees that if they have a correct outcome model then $Y_i A_i = \\hat{y}(\\textrm{covariates}_i)* A_i$ and so the whole thing would reduce zero.\n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: It does!\n\n|                                                                                            |                  |\n|:-------------------------------------------------------------------------------------------|:-----------------|\n|Outcome Formula                                                                             |Y ~ A + Z + W + M |\n|Exposure Formula                                                                            |A ~ X             |\n|Outcome Model Estimate                                                                      |1.005946          |\n|IPW Estimate                                                                                |1.952361          |\n|$\\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)}$                            |6.749474          |\n|$\\frac{1}{n}\\sum \\frac{\\hat{y}(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)}$ |6.749384          |\n|Difference                                                                                  |8.976111e-05      |\n:::\n:::\n\n\nFollowing this analysis our naive researcher thinks the causal estimate from the outcome model probably the right one. If it weren't then, $Y_i A_i \\neq \\hat{y}(\\textrm{covariates}_i)* A_i$ the whole thing does not reduce to zero. Instead we might observe something like the first column:\n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: \n\n|                                                                                            |           |             |\n|:-------------------------------------------------------------------------------------------|:----------|:------------|\n|Outcome Formula                                                                             |Y ~ A + M  |Y ~ A        |\n|Exposure Formula                                                                            |A ~ X      |A ~ M        |\n|Outcome Model Estimate                                                                      |4.973566   |4.973385     |\n|IPW Estimate                                                                                |1.952361   |4.97346      |\n|$\\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)}$                            |6.749474   |7.479902     |\n|$\\frac{1}{n}\\sum \\frac{\\hat{y}(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)}$ |7.49003    |7.479846     |\n|Difference                                                                                  |-0.7405556 |5.668737e-05 |\n:::\n:::\n\n\nNote the second column, this is not actually a way to tell if the outcome model is correct.\n\nNevertheless, we now have two of the three parts of the doubly robust estimator.\n\n### With Outcome Regression: The Full Estimator\n\nWe just saw how two parts of the doubly robust estimator add together to equal zero when the outcome model is correct. In the full doubly robust estimator we also add\n\n$$\n\\frac{1}{n}\\sum \\hat{y}_1(\\textrm{covariates}_i) - \\hat{y}_0(\\textrm{covariates}_i)\n$$\n\nSince the other parts are zero when the outcome model is correct, the doubly robust estimator produces an estimate of average causal effect based on just the above sum.\n\nSo the full estimator is:\n\n\n```{=tex}\n\\begin{aligned}\n\n(\\textrm{A})  \\hskip 2em &\\frac{1}{n}\\sum \\left[ \\hat{y}_1(\\textrm{covariates}_i) - \\hat{y}_0(\\textrm{covariates}_i) \\right]\\\\\n\n&\\quad\\quad \\uparrow \\textrm{Estimates correctly when the outcome model is correct} \\\\\n\n\\\\\n\n(\\textrm{B}) \\hskip 1.2em +&\\frac{1}{n}\\sum \\left[ \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)} - \\frac{Y_i(1 - A_i) }{1 - \\hat{e}(\\textrm{covariates}_i)} \\right]\\\\\n\n&\\quad\\quad \\uparrow \\textrm{Estimates correctly when the treatment model is correct} \\\\\n\n\\\\\n\n\n(\\textrm{C}) \\hskip 1.2em -&\\frac{1}{n}\\sum \\left[\\frac{\\hat{y}_1(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)} -  \\frac{\\hat{y}_0(\\textrm{covariates}_i)*(1 - A_i)}{1 - \\hat{e}(\\textrm{covariates}_i)} \\right] \\\\\n\n&\\quad\\quad \\uparrow \\textrm{Estimates correctly when both models are correct} \\\\\n\n\\\\\n\n\\end{aligned}\n```\n\n### Testing Doubly Robust Estimation\n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: Testing\n\n|                       |Accurate Models   |Inaccurate Exposure Model |Inaccurate Exposure Model |Very Inaccurate Exposure Model |Inaccurate Models |\n|:----------------------|:-----------------|:-------------------------|:-------------------------|:------------------------------|:-----------------|\n|Outcome Formula        |Y ~ A + Z + W + M |Y ~ A + Z + W + M         |Y ~ A + Z + W + M         |Y ~ A + Z + W + M              |Y ~ A             |\n|Exposure Formula       |A ~ Z + X + N     |A ~ X + N                 |A ~ Z                     |A ~ N * N + N                  |A ~ X             |\n|Outcome Model Estimate |1.005946          |1.005946                  |1.005946                  |1.005946                       |4.973385          |\n|IPW Estimate           |0.9699816         |1.934765                  |1.164451                  |5.065722                       |1.952361          |\n|A                      |1.005946          |1.005946                  |1.005946                  |1.005946                       |4.973385          |\n|B                      |0.9244188         |1.928329                  |1.285034                  |5.068746                       |2.002247          |\n|C                      |-0.9280126        |-1.941743                 |-1.287458                 |-5.067957                      |-5.004859         |\n|Doubly Robust Estimate |1.002352          |0.9925309                 |1.003522                  |1.006735                       |1.970774          |\n:::\n\n::: {.cell-output-display}\nTable: Testing\n\n|                       |Accurate Models   |Inaccurate Outcome Model |Inaccurate Outcome Model |Very Inaccurate Outcome Model |Inaccurate Models |Inaccurate Models |\n|:----------------------|:-----------------|:------------------------|:------------------------|:-----------------------------|:-----------------|:-----------------|\n|Outcome Formula        |Y ~ A + Z + W + M |Y ~ A + N                |Y ~ A * Z + W            |Y ~ A                         |Y ~ A             |Y ~ A + M         |\n|Exposure Formula       |A ~ Z + X + N     |A ~ Z + X + N            |A ~ Z + X + N            |A ~ Z + X + N                 |A ~ X             |A ~ 1             |\n|Outcome Model Estimate |1.005946          |5.055957                 |1.00563                  |4.973385                      |4.973385          |4.973566          |\n|IPW Estimate           |0.9699816         |0.9699816                |0.9699816                |0.9699816                     |1.952361          |4.973385          |\n|A                      |1.005946          |5.055957                 |1.000887                 |4.973385                      |4.973385          |4.973566          |\n|B                      |0.9244188         |0.9244188                |0.9244188                |0.9244188                     |2.002247          |4.973385          |\n|C                      |-0.9280126        |-5.029893                |-0.923734                |-4.947379                     |-5.004859         |-4.973385         |\n|Doubly Robust Estimate |1.002352          |0.9504826                |1.001572                 |0.9504245                     |1.970774          |4.973566          |\n:::\n:::\n\n\n## Works Cited {.appendix}\n\n(in progress)\n\nhttps://doi.org/10.1093/aje/kwq439\n\nhttps://www.degruyter.com/document/doi/10.1515/jci-2018-0016/html?lang=en\n\n## Code Appendix {.appendix}\n\n### Simulating Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 100000\nZ <- rnorm(n, 0, 1) # Z\nW <- rbinom(n, 1, .5) # W\n\nX <- rnorm(n, Z, 2)\n\nlog_odds_A <- .5 * Z + .5 * X\nodds_A <- exp(log_odds_A)\np_A <- odds_A / (1 + odds_A)\nA <- rbinom(n, 1, p_A) # A\n\nM <- rnorm(n, 20 - 2, .5)\n\nY <- rnorm(n, A + W + 2 * Z + 0.05 * M, .25)\n\ndata <- data.frame(A = (A), Y = Y, Z = Z, M = M, W = (W), X = X)\n```\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}