{
  "hash": "71a0273e1bd9d85e5dcfeba6f2c0ed6c",
  "result": {
    "markdown": "---\ntitle: \"Doubly Robust Estimators\"\ndescription: \"An Exploration of a Double Robust Estimator for Causal Inference\"\ndate: \"2023-04-17\"\n\ncategories:\n  - Data Science\n  - Statistics\nabout:\n  template: marquee\nexecute:\n  freeze: auto\n  echo: false\n  warning: false\n  message: false\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\nDoubly Robust estimation allows researchers to take advantage of both an outcome model and a model of treatment. If one or both of the models is correct, the doubly robust estimator will produce an accurate estimate of the causal effect. On the face of it the logic does not make sense. Consider a naive researcher who, not knowing anything about doubly robust estimators, creates two estimates of average causal effect. This is the causal diagram for our simulated data:\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Where Y is the outcome and A is a binary treatment. All relationships are linear.](index_files/figure-html/daggity-1.png){fig-alt='A causal graph with arrows from W, M, Z, and A to the outcome Y; an arrow from W to X; arrows from X and Z to A; and an arrow from A to M' width=672}\n:::\n:::\n\n\n### Boring Methods\n\nThe naive researcher uses uses thorough research and input from experts to come up with two models:\n\n1.  The outcome is affected by the treatment, Z, W, and M.\n\n    Y \\~ A + Z + W + M\n\n2.  The treatment an individual is assigned to is affected by X.\n\n    A \\~ X\n    \nSince we simulated the data we know that they have arrived at the correct model of the outcome, but an incorrect model of the treatment. Using these models the researcher performs linear regression and inverse probability weighting to arrive at two different estimates of average causal effect. \n\n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: The Researcher's Puzzling Result\n\n|                                            |                  |\n|:-------------------------------------------|:-----------------|\n|Outcome Formula                             |Y ~ A + Z + W + M |\n|Exposure Formula                            |A ~ X             |\n|Causal Effect Estimate from Outcome Model   |0.9997421         |\n|Causal Effect Estimate from Treatment Model |1.793059          |\n:::\n:::\n\n\nThe estimates are at odds and they can't tell which of their models is failing. Both models have equivalently tiny p-values, both models are based on strong evidence from experts. \n\n### One Part of The Doubly Robust Estimator\n\nThe researcher then figures out a way to make an ever worse estimator that will use both models.\n\n$$\n\\frac{1}{n}\\sum \\frac{\\hat{y}(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)} - \\frac{1}{n}\\sum \\frac{\\hat{y}(\\textrm{covariates}_i)*(1- A_i)}{1-\\hat{e}(\\textrm{covariates}_i)}\n$$\n\nWhere $\\hat{y}(\\textrm{covariates}_i)$ are the predicted values of the outcome for each individual $i$, $A_i$ are the treatments received, and $\\hat{e}(\\textrm{covariates}_i)$ are the probabilities the individual received the treatment $A = 1$. By using both the outcome and treatment models, the researcher has ensured that this estimator will fail if either the model is wrong. Not only will it fail, but it will fail by the same amount as the individual estimators. This is very important. \n\n### With IPW\n\nFor simplicity let's say IPW is \n\n$$\n\\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)}  - \\frac{1}{n}\\sum \\frac{Y_i (1-A_i)}{1-\\hat{e}(\\textrm{covariates}_i)}\n$$\n\nWhere $Y_i$ are the actual outcome values. If the treatment model is correct this will produce a correct estimate of average causal effect.\n\nFocus just on one side of the equation, and subtract the same side from the bad estimator above:\n\n$$\n\\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)} - \\frac{\\hat{y}(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)}\n$$\n\nOur researcher, sees that if they have a correct outcome model then $Y_i A_i = \\hat{y}(\\textrm{covariates}_i)* A_i$ and so the whole thing would reduce zero. \n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: It does!\n\n|                                                                                            |                  |\n|:-------------------------------------------------------------------------------------------|:-----------------|\n|Outcome Formula                                                                             |Y ~ A + Z + W + M |\n|Exposure Formula                                                                            |A ~ X             |\n|Outcome Model Estimate                                                                      |0.9997421         |\n|IPW Estimate                                                                                |1.793059          |\n|$\\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)}$                            |2.788935          |\n|$\\frac{1}{n}\\sum \\frac{\\hat{y}(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)}$ |2.788523          |\n|Difference                                                                                  |0.0004114241      |\n:::\n:::\n\n\nFollowing this analysis our naive researcher knows the causal estimate from the outcome model probably the right one. If it weren't then, $Y_i A_i \\neq \\hat{y}(\\textrm{covariates}_i)* A_i$ the whole thing does not reduce to zero. Instead we might observe something like the first column: \n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: \n\n|                                                                                            |           |             |\n|:-------------------------------------------------------------------------------------------|:----------|:------------|\n|Outcome Formula                                                                             |Y ~ A + M  |Y ~ A        |\n|Exposure Formula                                                                            |A ~ X      |A ~ M        |\n|Outcome Model Estimate                                                                      |2.462635   |2.462554     |\n|IPW Estimate                                                                                |1.793059   |2.462635     |\n|$\\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)}$                            |2.788935   |3.131932     |\n|$\\frac{1}{n}\\sum \\frac{\\hat{y}(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)}$ |3.128836   |3.131899     |\n|Difference                                                                                  |-0.3399016 |3.293283e-05 |\n:::\n:::\n\n\nIn the second column we see that this is not actually a sound method on its own.\n\n### Adding Outcome Regression\n\n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: It does!\n\n|                                                                            |          |\n|:---------------------------------------------------------------------------|:---------|\n|Outcome Formula                                                             |Y ~ A     |\n|Exposure Formula                                                            |A ~ X + Z |\n|Outcome Model Estimate                                                      |2.462554  |\n|IPW Estimate                                                                |1.0099    |\n|$\\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)}$            |3.131899  |\n|$\\frac{1}{n}\\sum \\hat{y}(\\textrm{covariates}_i)$                            |2.40087   |\n|$\\frac{\\hat{y}(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)}$ |3.134323  |\n|Difference                                                                  |2.398446  |\n:::\n:::\n\n\n\nFocusing again on just the $A = 1$ side of the equation:\n\n\n$$\n\\frac{1}{n}\\sum \\hat{y}(\\textrm{covariates}_i) - \\frac{\\hat{y}(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)}\n$$\nIf the exposure model is right $\\hat{e}(\\textrm{covariates}_i) = e(\\textrm{covariates}_i)$\n\n$$\n\\frac{1}{n}\\sum \\hat{y}(\\textrm{covariates}_i) (1- \\frac{A_i}{\\hat{e}(\\textrm{covariates}_i)})\n$$\n\n$$\n\\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)} + \\hat{y}(\\textrm{covariates}_i) - \\frac{\\hat{y}(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)}\n$$\n$$\n\\frac{Y_i A_i + \\hat{y}(\\textrm{covariates}_i)\\hat{e}(\\textrm{covariates}_i)}{\\hat{e}(\\textrm{covariates}_i)} +  - \\frac{\\hat{y}(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)}\n$$\n$$\nY_i A_i = \n$$\n\n\n## Works Cited {.appendix}\n\n(in progress)\n\nhttps://doi.org/10.1093/aje/kwq439  \n\n  \nhttps://www.degruyter.com/document/doi/10.1515/jci-2018-0016/html?lang=en\n\n\n\n## Code Appendix {.appendix}\n\n### Simulating Data\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 100000\nZ <- rnorm(n, 0, 1) # Z\nW <- rbinom(n, 1, .5) # W\n\nX <- rnorm(n, Z, 2)\n\nlog_odds_A <- .5 * Z + .5 * X\nodds_A <- exp(log_odds_A)\np_A <- odds_A / (1 + odds_A)\nA <- rbinom(n, 1, p_A) # A\n\nM <- rnorm(n, 20 - 2, .5)\n\nY <- rnorm(n, A + W + 2 * Z + 0.05 * M, .25)\n\ndata <- data.frame(A = (A), Y = Y, Z = Z, M = M, W = (W), X = X)\n```\n:::\n\n\n### Perform IPW and Outcome Regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_normal_methods <- function(data, outcome_formula, exposure_formula) {\n  outcome <- lm(outcome_formula)\n  ps_model <- glm(exposure_formula, family = \"binomial\")\n  \n  \n  data <- data %>%\n  mutate(ps = predict(ps_model, newdata = data, type = \"response\")) %>%\n  mutate(ipw = case_when(\n            A == 1 ~ 1/ps,\n            A == 0 ~ 1/(1-ps)\n        ))\n  \n  example_ipw <- lm(Y ~ A, data = data, weights = ipw)\n  # print(summary(example_ipw)$coefficients)\n  # print(summary(outcome)$coefficients)\n  mods <- t(c(outcome_formula,exposure_formula))\n  output <- as.data.frame(cbind(mods, outcome$coefficients[2], \n                                example_ipw$coefficients[2]))\n  names(output) <- c(\"Outcome Formula\",\"Exposure Formula\",\n                     \"Causal Effect Estimate from Outcome Model\", \n                     \"Causal Effect Estimate from Treatment Model\")\n  return(output)\n}\n```\n:::\n\n\n### Get the Second and Third Parts of the Doubly Robust Estimator\n\n::: {.cell}\n\n```{.r .cell-code}\nget_dr_parts2_3 <- function(data, outcome_formula, exposure_formula) {\n  outcome <- lm(outcome_formula)\n  ps_model <- glm(exposure_formula, family = \"binomial\")\n\n\n  data <- data %>%\n  mutate(ps = predict(ps_model, newdata = data, type = \"response\")) %>%\n  mutate(ipw = case_when(\n            A == 1 ~ 1/ps,\n            A == 0 ~ 1/(1-ps)\n        ))\n\n  example_ipw <- lm(Y ~ A, data = data, weights = ipw)\n\n  forceA0 <- data %>% mutate(A = 0)\n  forceA1 <- data %>% mutate(A = 1)\n\n  predA0 <- predict(outcome, newdata = forceA0)\n  predA1 <- predict(outcome, newdata = forceA1)\n\n  DR1 <-\n    (((    data$A) * data$Y) / (    data$ps)) -      # IPW part\n    ((predA1 * (data$A - data$ps))) / (    data$ps)  # Other thing\n  DR0 <-\n    (((1 - data$A) * data$Y) / (1 - data$ps)) +      # IPW part\n    ((predA0 * (data$A - data$ps))) / (1 - data$ps)  # Other thing\n\n  Estimator1 <- predA1 + ((data$Y * data$A) / (data$ps)) - ((predA1 * data$A) / data$ps)\n  Estimator0 <- predA0 + ((data$Y * (1 - data$A)) / (1 - data$ps)) - ((predA0 * (1 - data$A)) / (1 - data$ps))\n\n\n  part1 <- predA1\n  part2 <- ((data$Y * data$A) / (data$ps))\n  part3 <- -((predA1 * data$A) / data$ps)\n  \n  part1A0 <- predA0\n  part2A0 <- ((data$Y * (1 - data$A)) / (1 - data$ps))\n  part3A0 <- -((predA0 * (1 - data$A)) / (1 - data$ps))\n  \n  partdr1 <- mean(part1) - mean(part1A0)\n  partdr2 <- mean((data$Y * data$A) / (data$ps)) - mean((data$Y * (1 - data$A)) / (1 - data$ps))\n  partdr3 <- mean(-((predA1 * data$A) / data$ps)) - mean(-((predA0 * (1 - data$A)) / (1 - data$ps)))\n\n  mods <- t(c(outcome_formula,exposure_formula))\n  output <- as.data.frame(cbind(mods, outcome$coefficients[2], example_ipw$coefficients[2], mean(part2), mean(-part3), mean(part2+part3)))\n  names(output) <- c(\"Outcome Formula\",\"Exposure Formula\", \"Outcome Model Estimate\", \"IPW Estimate\", \"$B$\", \"$C$\", \"D\")\n  return(output)\n```\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}