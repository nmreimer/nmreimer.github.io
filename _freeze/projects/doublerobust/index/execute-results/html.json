{
  "hash": "4fb2958755761eb7ac9f9b5e753a6932",
  "result": {
    "markdown": "---\ntitle: \"Doubly Robust Estimators\"\ndescription: \"An Exploration of a Double Robust Estimator for Causal Inference\"\ndate: \"2023-04-17\"\n\ncategories:\n  - Data Science\n  - Statistics\nabout:\n  template: marquee\nexecute:\n  freeze: auto\n  echo: false\n  warning: false\n  message: false\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n### Doubly Robust Estimators\n\nDoubly Robust estimation allows researchers to take advantage of both an outcome model and a model of treatment. If one or both of the models is correct, the doubly robust estimator will produce an accurate estimate of the causal effect. Here I'll focus on doubly robust estimation for a quantitative outcome and a binary treatment. Here is one such estimator:\n\n\n```{=tex}\n\\begin{aligned}\n\n&\\frac{1}{n}\\sum \\left[ \\hat{y}_1(\\textrm{covariates}_i) + \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)} - \\frac{\\hat{y}_1(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)} \\right] \\\\\n\n-&\\frac{1}{n}\\sum \\left[ \\hat{y}_0(\\textrm{covariates}_i) + \\frac{Y_i(1 - A_i) }{1 - \\hat{e}(\\textrm{covariates}_i)} - \\frac{\\hat{y}_0(\\textrm{covariates}_i)*(1 - A_i)}{1 - \\hat{e}(\\textrm{covariates}_i)} \\right] \\\\\n\n&\\quad\\quad\\quad\\quad\\quad\\quad (\\textrm{A}) \\quad\\quad\\quad\\quad\\quad\\quad (\\textrm{B}) \\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad (\\textrm{C})\n\n\n\\end{aligned}\n```\n\n\nOr, alternatively: \n\n\n```{=tex}\n\\begin{aligned}\n\n(\\textrm{A})  \\hskip 2em &\\frac{1}{n}\\sum \\left[ \\hat{y}_1(\\textrm{covariates}_i) - \\hat{y}_0(\\textrm{covariates}_i) \\right]\\\\\n\n\\\\\n\n(\\textrm{B}) \\hskip 1.2em +&\\frac{1}{n}\\sum \\left[ \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)} - \\frac{Y_i(1 - A_i) }{1 - \\hat{e}(\\textrm{covariates}_i)} \\right]\\\\\n\n\\\\\n\n\n(\\textrm{C}) \\hskip 1.2em -&\\frac{1}{n}\\sum \\left[\\frac{\\hat{y}_1(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)} -  \\frac{\\hat{y}_0(\\textrm{covariates}_i)*(1 - A_i)}{1 - \\hat{e}(\\textrm{covariates}_i)} \\right] \\\\\n\n\\\\\n\n\\end{aligned}\n```\n\n\n\n\nWhere\n\n-   $\\hat{y}_1(\\textrm{covariates}_i)$ are the predicted values for each individual $i$ with treatment $1$.\n\n-   $Y_i$ and $A_i$ are, respectively, the actual outcome and treatment values for each individual.\n\n-   $\\hat{e}(\\textrm{covariates}_i)$ are the predicted propensity scores for each individual $i$.\n\nThe rest of this page will attempt to explain how the doubly robust property works in this estimator.\n\n### Simulation\n\nThis is the causal diagram for our simulated data:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Where Y is the outcome and A is a binary treatment. All relationships are linear.](index_files/figure-html/daggity-1.png){fig-alt='A causal graph with arrows from W, M, Z, and A to the outcome Y; an arrow from W to X; arrows from X, Z, and N to A' width=672}\n:::\n:::\n\n\n### Boring Methods\n\nConsider a naive researcher who, not knowing anything about doubly robust estimators, creates two estimates of average causal effect. The naive researcher uses uses thorough research and input from experts to come up with two models:\n\n1.  The outcome is affected by the treatment, Z, W, and M.\n\n    Y \\~ A + Z + W + M\n\n2.  The treatment an individual is assigned to is affected by X.\n\n    A \\~ X\n\nSince we simulated the data we know that they have arrived at the correct model of the outcome, but an incorrect model of the treatment. Using these models the researcher performs linear regression and inverse probability weighting to arrive at two different estimates of average causal effect.\n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: The Researcher's Puzzling Result\n\n|                                            |                  |\n|:-------------------------------------------|:-----------------|\n|Outcome Formula                             |Y ~ A + Z + W + M |\n|Exposure Formula                            |A ~ X             |\n|Causal Effect Estimate from Outcome Model   |1.006395          |\n|Causal Effect Estimate from Treatment Model |4.36404           |\n:::\n:::\n\n\nThe estimates are at odds and they can't tell which of their models is failing. Both models have equivalently tiny p-values, both models are based on strong evidence from experts.\n\n### One Part of The Doubly Robust Estimator\n\nThe researcher then figures out a way to make an ever worse estimator that will use both models.\n\n$$\n (\\textrm{C}) \\quad\\quad \\frac{1}{n}\\sum \\frac{\\hat{y}_1(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)} - \\frac{1}{n}\\sum \\frac{\\hat{y}_0(\\textrm{covariates}_i)*(1- A_i)}{1-\\hat{e}(\\textrm{covariates}_i)}\n$$\n\nBy using both the outcome and treatment models, the researcher has ensured that this estimator will fail if either the model is wrong. Not only will it fail, but it will fail by the same amount as the individual estimators. This is important.\n\n### With IPW\n\nFor simplicity let's say IPW is\n\n$$\n(\\textrm{B}) \\quad\\quad  \\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)}  - \\frac{1}{n}\\sum \\frac{Y_i (1-A_i)}{1-\\hat{e}(\\textrm{covariates}_i)}\n$$\n\nWhere $Y_i$ are the actual outcome values. If the treatment model is correct this will produce a correct estimate of average causal effect.\n\nFocus just on one side of the equation, and subtract the same side of the bad estimator above:\n\n$$\n\\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)} - \\frac{\\hat{y}_1(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)}\n$$\n\n$$\n(\\textrm{B}_1) - (\\textrm{C}_1)\n$$\n\nThe researcher sees that if they have a correct outcome model then $Y_i A_i = \\hat{y}(\\textrm{covariates}_i)* A_i$ and so the whole thing would reduce zero.\n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: It does!\n\n|                                                                                            |                  |\n|:-------------------------------------------------------------------------------------------|:-----------------|\n|Outcome Formula                                                                             |Y ~ A + Z + W + M |\n|Exposure Formula                                                                            |A ~ X             |\n|Outcome Model Estimate                                                                      |1.006395          |\n|IPW Estimate                                                                                |4.36404           |\n|$\\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)}$                            |8.175909          |\n|$\\frac{1}{n}\\sum \\frac{\\hat{y}(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)}$ |8.177796          |\n|Difference                                                                                  |-0.001887749      |\n:::\n:::\n\n\nFollowing this analysis our naive researcher thinks the causal estimate from the outcome model probably the right one. If it weren't then, $Y_i A_i \\neq \\hat{y}(\\textrm{covariates}_i)* A_i$ the whole thing does not reduce to zero. Instead we might observe something like the first column:\n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: \n\n|                                                                                            |              |             |\n|:-------------------------------------------------------------------------------------------|:-------------|:------------|\n|Outcome Formula                                                                             |Y ~ A + X     |Y ~ A        |\n|Exposure Formula                                                                            |A ~ X + Z + N |A ~ M        |\n|Outcome Model Estimate                                                                      |4.33691       |3.982831     |\n|IPW Estimate                                                                                |0.9860699     |3.982965     |\n|$\\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)}$                            |6.493073      |7.987311     |\n|$\\frac{1}{n}\\sum \\frac{\\hat{y}(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)}$ |8.218912      |7.987186     |\n|Difference                                                                                  |-1.725839     |0.0001254348 |\n:::\n:::\n\n\nNote the second column, this is not actually a way to tell if the outcome model is correct.\n\nNevertheless, we now have two of the three parts of the doubly robust estimator.\n\n### With Outcome Regression: The Full Estimator\n\nWe just saw how two parts of the doubly robust estimator add together to equal zero when the outcome model is correct. In the full doubly robust estimator we also add\n\n$$\n(\\textrm{A}) \\quad\\quad  \\frac{1}{n}\\sum \\hat{y}_1(\\textrm{covariates}_i) - \\hat{y}_0(\\textrm{covariates}_i)\n$$\n\nSince the other parts are zero when the outcome model is correct, the doubly robust estimator produces an estimate of average causal effect based on just the above sum.\n\nSo the full estimator is:\n\n\n```{=tex}\n\\begin{aligned}\n\n(\\textrm{A})  \\hskip 2em &\\frac{1}{n}\\sum \\left[ \\hat{y}_1(\\textrm{covariates}_i) - \\hat{y}_0(\\textrm{covariates}_i) \\right]\\\\\n\n&\\quad\\quad \\uparrow \\textrm{Estimates correctly when the outcome model is correct} \\\\\n\n\\\\\n\n(\\textrm{B}) \\hskip 1.2em +&\\frac{1}{n}\\sum \\left[ \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)} - \\frac{Y_i(1 - A_i) }{1 - \\hat{e}(\\textrm{covariates}_i)} \\right]\\\\\n\n&\\quad\\quad \\uparrow \\textrm{Estimates correctly when the treatment model is correct} \\\\\n\n\\\\\n\n\n(\\textrm{C}) \\hskip 1.2em -&\\frac{1}{n}\\sum \\left[\\frac{\\hat{y}_1(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)} -  \\frac{\\hat{y}_0(\\textrm{covariates}_i)*(1 - A_i)}{1 - \\hat{e}(\\textrm{covariates}_i)} \\right] \\\\\n\n&\\quad\\quad \\uparrow \\textrm{Estimates correctly when both models are correct} \\\\\n\n\\\\\n\n\\end{aligned}\n```\n\n\nLaid out like this, it is relatively simple to see how doubly robust estimation works. For example, if a researcher has an accurate exposure model and an inaccurate outcome model, $(\\textrm{A})$ and $(\\textrm{C})$ cancel each other out and we are left with just the accurate estimate based on the exposure model: $(\\textrm{C})$. Take a little bit to think about the other possibilities yourself. \n\n### Testing Doubly Robust Estimation\n\n\n::: {.cell}\n::: {.cell-output-display}\n|                       |Accurate Models   |Inaccurate Exposure Model |Inaccurate Exposure Model |Very Inaccurate Exposure Model |Inaccurate Models |\n|:----------------------|:-----------------|:-------------------------|:-------------------------|:------------------------------|:-----------------|\n|Outcome Formula        |Y ~ A + Z + W + M |Y ~ A + Z + W + M         |Y ~ A + Z + W + M         |Y ~ A + Z + W + M              |Y ~ A             |\n|Exposure Formula       |A ~ Z + X + N     |A ~ X + N                 |A ~ Z                     |A ~ N * N + N                  |A ~ X             |\n|Outcome Model Estimate |1.006395          |1.006395                  |1.006395                  |1.006395                       |3.982831          |\n|IPW Estimate           |0.9860699         |4.384825                  |1.219445                  |3.99768                        |4.36404           |\n|A                      |1.006395          |1.006395                  |1.006395                  |1.006395                       |3.982831          |\n|B                      |1.054308          |4.395095                  |1.225058                  |3.997546                       |4.371975          |\n|C                      |-1.058516         |-4.397362                 |-1.226231                 |-3.998397                      |-3.991018         |\n|Doubly Robust Estimate |1.002187          |1.004128                  |1.005223                  |1.005544                       |4.363788          |\n:::\n:::\n\n\nThe real causal effect in our simulated data is 1. With inaccurate exposure models and an accurate outcome model we observe, just as we would expect, $(\\textrm{B})$ and $(\\textrm{C})$ cancel out and we are left with an estimate based on $(\\textrm{A})$. When both models are inaccurate this does not happen. \n\n\n::: {.cell}\n::: {.cell-output-display}\n|                       |Accurate Models   |Inaccurate Outcome Model |Inaccurate Outcome Model |Very Inaccurate Outcome Model |Inaccurate Models |Inaccurate Models |\n|:----------------------|:-----------------|:------------------------|:------------------------|:-----------------------------|:-----------------|:-----------------|\n|Outcome Formula        |Y ~ A + Z + W + M |Y ~ A + N                |Y ~ A * Z + W            |Y ~ A                         |Y ~ A             |Y ~ A             |\n|Exposure Formula       |A ~ Z + X + N     |A ~ Z + X + N            |A ~ Z + X + N            |A ~ Z + X + N                 |A ~ X             |A ~ M             |\n|Outcome Model Estimate |1.006395          |3.997467                 |1.005835                 |3.982831                      |3.982831          |3.982831          |\n|IPW Estimate           |0.9860699         |0.9860699                |0.9860699                |0.9860699                     |4.36404           |3.982965          |\n|A                      |1.006395          |3.997467                 |1.006498                 |3.982831                      |3.982831          |3.982831          |\n|B                      |1.054308          |1.054308                 |1.054308                 |1.054308                      |4.371975          |3.982964          |\n|C                      |-1.058516         |-4.067476                |-1.059288                |-4.052766                     |-3.991018         |-3.982831         |\n|Doubly Robust Estimate |1.002187          |0.9842992                |1.001518                 |0.9843736                     |4.363788          |3.982965          |\n:::\n:::\n\n\nWhen we have an accurate exposure and an inaccurate outcome model, $(\\textrm{A})$ and $(\\textrm{C})$ cancel out and we are left with an estimate based on $(\\textrm{B})$. \n\n\n## Sources {.appendix}\n\n\"Doubly Robust Estimation of Causal Effects\" by Funk et al. and \"A Falsifiability Characterization of Double Robustness Through Logical Operators\" by Frangakis were used heavily in this project. My goal in this project was essentially to create an explanation of double robustness that combined Frangakis' logical framework with the more numerical and simulation-based approach of the Funk paper.\n\n[Doubly Robust Estimation of Causal Effects](https://doi.org/10.1093/aje/kwq439)\n\n[A Falsifiability Characterization of Double Robustness Through Logical Operators](https://www.degruyter.com/document/doi/10.1515/jci-2018-0016/html?lang=en)\n\n## Code {.appendix}\n\n### Simulating Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(7)\nn <- 100000\nZ <- rnorm(n, 1, 2) # Z\n\nW <- rbinom(n, 1, .5) # W\n\nX <- rnorm(n, 2*W, 2) # X\n\nM <- rnorm(n, 20, 1) # M\n\nN <- rnorm(n, 10, 2) # N\n\nlog_odds_A <- .25 * Z + .5 * X + .1 * N\nodds_A <- exp(log_odds_A)\np_A <- odds_A / (1 + odds_A)\nA <- rbinom(n, 1, p_A) # A\n\n\n\nY <- rnorm(n, A + W + 2 * Z + 0.05 * M + rnorm(n, 2, 1), .25) # Y\n\ndata <- data.frame(A = (A), Y = Y, Z = Z, M = M, W = (W), X = X)\n```\n:::\n\n\n### Function for Normal Methods\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_normal_methods <- function(data, outcome_formula, exposure_formula) {\n  outcome <- lm(outcome_formula)\n  ps_model <- glm(exposure_formula, family = \"binomial\")\n  \n  \n  data <- data %>%\n  mutate(ps = predict(ps_model, newdata = data, type = \"response\")) %>%\n  mutate(ipw = case_when(\n            A == 1 ~ 1/ps,\n            A == 0 ~ 1/(1-ps)\n        ))\n  \n  example_ipw <- lm(Y ~ A, data = data, weights = ipw)\n  # print(summary(example_ipw)$coefficients)\n  # print(summary(outcome)$coefficients)\n  mods <- t(c(outcome_formula,exposure_formula))\n  output <- as.data.frame(cbind(mods, outcome$coefficients[2], example_ipw$coefficients[2]))\n  names(output) <- c(\"Outcome Formula\",\"Exposure Formula\",\"Causal Effect Estimate from Outcome Model\", \"Causal Effect Estimate from Treatment Model\")\n  return(output)\n}\n```\n:::\n\n\n### Function for Two Parts of DR Estimator\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_dr_parts2_3 <- function(data, outcome_formula, exposure_formula) {\n  outcome <- lm(outcome_formula)\n  ps_model <- glm(exposure_formula, family = \"binomial\")\n  \n  forceA0 <- data %>% mutate(A = 0)\n  forceA1 <- data %>% mutate(A = 1)\n\n  predA0 <- predict(outcome, newdata = forceA0)\n  predA1 <- predict(outcome, newdata = forceA1)\n\n  data <- data %>%\n  mutate(ps = predict(ps_model, newdata = data, type = \"response\")) %>%\n  mutate(ipw = case_when(\n            A == 1 ~ 1/ps,\n            A == 0 ~ 1/(1-ps)\n        ))\n  part1 <- predA1\n  part2 <- ((data$Y * data$A) / (data$ps))\n  part3 <- -((predA1 * data$A) / data$ps)\n\n\n  example_ipw <- lm(Y ~ A, data = data, weights = ipw)\n\n  mods <- t(c(outcome_formula,exposure_formula))\n  output <- as.data.frame(cbind(mods, outcome$coefficients[2], example_ipw$coefficients[2], mean(part2), mean(-part3), mean(part2+part3)))\n  names(output) <- c(\"Outcome Formula\",\"Exposure Formula\", \"Outcome Model Estimate\", \"IPW Estimate\", \"$B$\", \"$C$\", \"D\")\n  return(output)\n}\n```\n:::\n\n\n### Function for All Parts of DR Estimator\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_dr_parts <- function(data, outcome_formula, exposure_formula) {\n  outcome <- lm(outcome_formula)\n  ps_model <- glm(exposure_formula, family = \"binomial\")\n\n\n  data <- data %>%\n  mutate(ps = predict(ps_model, newdata = data, type = \"response\")) %>%\n  mutate(ipw = case_when(\n            A == 1 ~ 1/ps,\n            A == 0 ~ 1/(1-ps)\n        ))\n\n  example_ipw <- lm(Y ~ A, data = data, weights = ipw)\n\n  forceA0 <- data %>% mutate(A = 0)\n  forceA1 <- data %>% mutate(A = 1)\n\n  predA0 <- predict(outcome, newdata = forceA0)\n  predA1 <- predict(outcome, newdata = forceA1)\n\n  DR1 <-\n    (((    data$A) * data$Y) / (    data$ps)) -      # IPW part\n    ((predA1 * (data$A - data$ps))) / (    data$ps)  # Other thing\n  DR0 <-\n    (((1 - data$A) * data$Y) / (1 - data$ps)) +      # IPW part\n    ((predA0 * (data$A - data$ps))) / (1 - data$ps)  # Other thing\n\n  Estimator1 <- predA1 + ((data$Y * data$A) / (data$ps)) - ((predA1 * data$A) / data$ps)\n  Estimator0 <- predA0 + ((data$Y * (1 - data$A)) / (1 - data$ps)) - ((predA0 * (1 - data$A)) / (1 - data$ps))\n\n\n  part1 <- predA1\n  part2 <- ((data$Y * data$A) / (data$ps))\n  part3 <- -((predA1 * data$A) / data$ps)\n  \n  part1A0 <- predA0\n  part2A0 <- ((data$Y * (1 - data$A)) / (1 - data$ps))\n  part3A0 <- -((predA0 * (1 - data$A)) / (1 - data$ps))\n  \n  partdr1 <- mean(part1) - mean(part1A0)\n  partdr2 <- mean((data$Y * data$A) / (data$ps)) - mean((data$Y * (1 - data$A)) / (1 - data$ps))\n  partdr3 <- mean(-((predA1 * data$A) / data$ps)) - mean(-((predA0 * (1 - data$A)) / (1 - data$ps)))\n\n  mods <- t(c(outcome_formula,exposure_formula))\n  output <- as.data.frame(cbind(mods, outcome$coefficients[2], example_ipw$coefficients[2], partdr1, partdr2, partdr3, sum(partdr1, partdr2, partdr3)))\n  \n  names(output) <- c(\"Outcome Formula\",\"Exposure Formula\", \"Outcome Model Estimate\", \"IPW Estimate\", \"$B$\", \"$C$\", \"D\", \"E\")\n  return(output)\n}\n```\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}