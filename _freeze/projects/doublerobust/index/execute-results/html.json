{
  "hash": "73a06873fd5a167e3662112d2b27eb32",
  "result": {
    "markdown": "---\ntitle: \"Doubly Robust Estimators\"\ndescription: \"An Exploration of a Double Robust Estimator for Causal Inference\"\ndate: \"2023-04-17\"\n\ncategories:\n  - Data Science\n  - Statistics\nabout:\n  template: marquee\nexecute:\n  freeze: auto\n  echo: false\n  warning: false\n  message: false\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\nDoubly Robust estimation allows researchers to take advantage of both an outcome model and a model of treatment. If one or both of the models is correct, the doubly robust estimator will produce an accurate estimate of the causal effect. On the face of it the logic does not make sense. Consider a naive researcher who, not knowing anything about doubly robust estimators, creates two estimates of average causal effect. This is the causal diagram for our simulated data:\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Where Y is the outcome and A is a binary treatment. All relationships are linear.](index_files/figure-html/daggity-1.png){fig-alt='A causal graph with arrows from W, M, Z, and A to the outcome Y; an arrow from W to X; arrows from X and Z to A; and an arrow from A to M' width=672}\n:::\n:::\n\n\n### Boring Methods\n\nThe naive researcher uses uses thorough research and input from experts to come up with two models:\n\n1.  The outcome is affected by the treatment, Z, W, and M.\n\n    Y \\~ A + Z + W + M\n\n2.  The treatment an individual is assigned to is affected by X.\n\n    A \\~ X\n    \nSince we simulated the data we know that they have arrived at the correct model of the outcome, but an incorrect model of the treatment. Using these models the researcher performs linear regression and inverse probability weighting to arrive at two different estimates of average causal effect. \n\n\n\n::: {.cell caption='The Researcher\\'s Puzzling Result'}\n::: {.cell-output-display}\nTable: The Researcher's Puzzling Result\n\n|                                            |                  |\n|:-------------------------------------------|:-----------------|\n|Outcome Formula                             |Y ~ A + Z + W + M |\n|Exposure Formula                            |A ~ X             |\n|Causal Effect Estimate from Outcome Model   |0.9998826         |\n|Causal Effect Estimate from Treatment Model |1.784511          |\n:::\n:::\n\n\nThe estimates are at odds and they can't tell which of their models is failing. Both models have equivalently tiny p-values, both models are based on strong evidence from experts. \n\n### The First Part of The Doubly Robust Estimator\n\nThe researcher then figures out a way to make an ever worse estimator that will use both models.\n\n$$\n\\frac{1}{n}\\sum \\frac{\\hat{y}(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)} - \\frac{1}{n}\\sum \\frac{\\hat{y}(\\textrm{covariates}_i)*(1- A_i)}{1-\\hat{e}(\\textrm{covariates}_i)}\n$$\n\nWhere $\\hat{y}(\\textrm{covariates}_i)$ are the predicted values of the outcome for each individual $i$, $A_i$ are the treatments received, and $\\hat{e}(\\textrm{covariates}_i)$ are the probabilities the individual received the treatment $A = 1$. By using both the outcome and treatment models, the researcher has ensured that this estimator will fail if either the model is wrong. Not only will it fail, but it will fail by the same amount as the individual estimators. This is very important. \n\n#### Failing the Same\n\nFor simplicity let's say IPW is \n\n$$\n\\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)}  - \\frac{1}{n}\\sum \\frac{Y_i (1-A_i)}{1-\\hat{e}(\\textrm{covariates}_i)}\n$$\n\nWhere $Y_i$ are the actual outcome values. If the treatment model is correct this will produce a correct estimate of average causal effect.\n\nFocus just on one side of the equation, and subtract the same side from the bad estimator above:\n\n$$\n\\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)} - \\frac{\\hat{y}(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)}\n$$\n\nOur researcher, sees that if they have a correct outcome model then $Y_i A_i = \\hat{y}(\\textrm{covariates}_i)* A_i$ and so the whole thing would reduce zero. \n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: It does!\n\n|                                                                                             |A                     |\n|:--------------------------------------------------------------------------------------------|:---------------------|\n|Outcome Formula                                                                              |Y ~ A + Z + W + M     |\n|Exposure Formula                                                                             |A ~ X                 |\n|Outcome Model Estimate                                                                       |0.999882632955987     |\n|IPW Estimate                                                                                 |1.7845109587187       |\n|$\\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)}$                             |2.80665032904263      |\n|$-\\frac{1}{n}\\sum \\frac{\\hat{y}(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)}$ |2.80719763152316      |\n|Difference                                                                                   |-0.000547302480528045 |\n:::\n:::\n\n\n## Works Cited {.appendix}\n\n(in progress)\n\nhttps://doi.org/10.1093/aje/kwq439\nhttps://www.degruyter.com/document/doi/10.1515/jci-2018-0016/html?lang=en\n\n\n\n## Code Appendix {.appendix}\n\n### Simulating Data\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 100000\nZ <- rnorm(n, 0, 1) # Z\nW <- rbinom(n, 1, .5) # W\n\nX <- rnorm(n, Z, 2)\n\nlog_odds_A <- .5 * Z + .5 * X\nodds_A <- exp(log_odds_A)\np_A <- odds_A / (1 + odds_A)\nA <- rbinom(n, 1, p_A) # A\n\nM <- rnorm(n, 20 - 2, .5)\n\nY <- rnorm(n, A + W + 2 * Z + 0.05 * M, .25)\n\ndata <- data.frame(A = (A), Y = Y, Z = Z, M = M, W = (W), X = X)\n```\n:::\n\n\n### Perform IPW and Outcome Regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_normal_methods <- function(data, outcome_formula, exposure_formula) {\n  outcome <- lm(outcome_formula)\n  ps_model <- glm(exposure_formula, family = \"binomial\")\n  \n  \n  data <- data %>%\n  mutate(ps = predict(ps_model, newdata = data, type = \"response\")) %>%\n  mutate(ipw = case_when(\n            A == 1 ~ 1/ps,\n            A == 0 ~ 1/(1-ps)\n        ))\n  \n  example_ipw <- lm(Y ~ A, data = data, weights = ipw)\n  # print(summary(example_ipw)$coefficients)\n  # print(summary(outcome)$coefficients)\n  mods <- t(c(outcome_formula,exposure_formula))\n  output <- as.data.frame(cbind(mods, outcome$coefficients[2], \n                                example_ipw$coefficients[2]))\n  names(output) <- c(\"Outcome Formula\",\"Exposure Formula\",\n                     \"Causal Effect Estimate from Outcome Model\", \n                     \"Causal Effect Estimate from Treatment Model\")\n  return(output)\n}\n```\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}