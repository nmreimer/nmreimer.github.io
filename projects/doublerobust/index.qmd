---
title: "Doubly Robust Estimators"
description: "An Exploration of a Double Robust Estimator for Causal Inference"
date: "2023-04-17"

categories:
  - Data Science
  - Statistics
about:
  template: marquee
execute:
  freeze: auto
  echo: false
  warning: false
  message: false
---

```{r packages}
library(dplyr)
library(ggplot2)
library(dagitty)
library(ggdag)
library(lemon)
knit_print.data.frame <- lemon_print

```
```{r simulate data}
n <- 100000
Z <- rnorm(n, 0, 1) # Z
W <- rbinom(n, 1, .5) # W

X <- rnorm(n, Z, 2)

log_odds_A <- .5 * Z + .5 * X
odds_A <- exp(log_odds_A)
p_A <- odds_A / (1 + odds_A)
A <- rbinom(n, 1, p_A) # A

M <- rnorm(n, 20 - 2, .5)

Y <- rnorm(n, A + W + 2 * Z + 0.05 * M, .25)

data <- data.frame(A = (A), Y = Y, Z = Z, M = M, W = (W), X = X)
```
```{r normal methods function}
get_normal_methods <- function(data, outcome_formula, exposure_formula) {
  outcome <- lm(outcome_formula)
  ps_model <- glm(exposure_formula, family = "binomial")
  
  
  data <- data %>%
  mutate(ps = predict(ps_model, newdata = data, type = "response")) %>%
  mutate(ipw = case_when(
            A == 1 ~ 1/ps,
            A == 0 ~ 1/(1-ps)
        ))
  
  example_ipw <- lm(Y ~ A, data = data, weights = ipw)
  # print(summary(example_ipw)$coefficients)
  # print(summary(outcome)$coefficients)
  mods <- t(c(outcome_formula,exposure_formula))
  output <- as.data.frame(cbind(mods, outcome$coefficients[2], example_ipw$coefficients[2]))
  names(output) <- c("Outcome Formula","Exposure Formula","Causal Effect Estimate from Outcome Model", "Causal Effect Estimate from Treatment Model")
  return(output)
}
```
```{r get dr parts 2&3}
get_dr_parts2_3 <- function(data, outcome_formula, exposure_formula) {
  outcome <- lm(outcome_formula)
  ps_model <- glm(exposure_formula, family = "binomial")


  data <- data %>%
  mutate(ps = predict(ps_model, newdata = data, type = "response")) %>%
  mutate(ipw = case_when(
            A == 1 ~ 1/ps,
            A == 0 ~ 1/(1-ps)
        ))

  example_ipw <- lm(Y ~ A, data = data, weights = ipw)

  forceA0 <- data %>% mutate(A = 0)
  forceA1 <- data %>% mutate(A = 1)

  predA0 <- predict(outcome, newdata = forceA0)
  predA1 <- predict(outcome, newdata = forceA1)

  DR1 <-
    (((    data$A) * data$Y) / (    data$ps)) -      # IPW part
    ((predA1 * (data$A - data$ps))) / (    data$ps)  # Other thing
  DR0 <-
    (((1 - data$A) * data$Y) / (1 - data$ps)) +      # IPW part
    ((predA0 * (data$A - data$ps))) / (1 - data$ps)  # Other thing

  Estimator1 <- predA1 + ((data$Y * data$A) / (data$ps)) - ((predA1 * data$A) / data$ps)
  Estimator0 <- predA0 + ((data$Y * (1 - data$A)) / (1 - data$ps)) - ((predA0 * (1 - data$A)) / (1 - data$ps))


  part1 <- predA1
  part2 <- ((data$Y * data$A) / (data$ps))
  part3 <- -((predA1 * data$A) / data$ps)
  
  part1A0 <- predA0
  part2A0 <- ((data$Y * (1 - data$A)) / (1 - data$ps))
  part3A0 <- -((predA0 * (1 - data$A)) / (1 - data$ps))
  
  partdr1 <- mean(part1) - mean(part1A0)
  partdr2 <- mean((data$Y * data$A) / (data$ps)) - mean((data$Y * (1 - data$A)) / (1 - data$ps))
  partdr3 <- mean(-((predA1 * data$A) / data$ps)) - mean(-((predA0 * (1 - data$A)) / (1 - data$ps)))

  mods <- t(c(outcome_formula,exposure_formula))
  output <- as.data.frame(cbind(mods, outcome$coefficients[2], example_ipw$coefficients[2], mean(part2), mean(-part3), mean(part2+part3)))
  names(output) <- c("Outcome Formula","Exposure Formula", "Outcome Model Estimate", "IPW Estimate", "$B$", "$C$", "D")
  return(output)
}

```



Doubly Robust estimation allows researchers to take advantage of both an outcome model and a model of treatment. If one or both of the models is correct, the doubly robust estimator will produce an accurate estimate of the causal effect. On the face of it the logic does not make sense. Consider a naive researcher who, not knowing anything about doubly robust estimators, creates two estimates of average causal effect. This is the causal diagram for our simulated data:


```{r daggity}
#| fig-alt: "A causal graph with arrows from W, M, Z, and A to the outcome Y; an arrow from W to X; arrows from X and Z to A; and an arrow from A to M"
#| fig-cap: "Where Y is the outcome and A is a binary treatment. All relationships are linear."

dag <- dagitty('dag { bb="0,0,1,1"
A [exposure,pos="0.1,0.5"]
M [pos="0.5,0.4"]
W [pos="0.9,0.35"]
X [pos="0.1,0.35"]
Y [outcome,pos="0.9,0.5"]
Z [pos="0.5,0.6"]
A -> M
A -> Y
M -> Y
W -> X
W -> Y
X -> A
Z -> A
Z -> Y
}')


ggdag(dag)  +
  theme_dag_blank() +
  geom_dag_point(color = "lightblue1") +
  geom_dag_text(color = "black")
  
```

### Boring Methods

The naive researcher uses uses thorough research and input from experts to come up with two models:

1.  The outcome is affected by the treatment, Z, W, and M.

    Y \~ A + Z + W + M

2.  The treatment an individual is assigned to is affected by X.

    A \~ X
    
Since we simulated the data we know that they have arrived at the correct model of the outcome, but an incorrect model of the treatment. Using these models the researcher performs linear regression and inverse probability weighting to arrive at two different estimates of average causal effect. 


```{r, render=lemon_print}
#| caption: "The Researcher's Puzzling Result"
ace_estimates_1 <- as.data.frame(t(get_normal_methods(data, Y ~ A + Z + W + M, A ~ X)))
colnames(ace_estimates_1) <- ""
ace_estimates_1
```

The estimates are at odds and they can't tell which of their models is failing. Both models have equivalently tiny p-values, both models are based on strong evidence from experts. 

### The First Part of The Doubly Robust Estimator

The researcher then figures out a way to make an ever worse estimator that will use both models.

$$
\frac{1}{n}\sum \frac{\hat{y}(\textrm{covariates}_i)*A_i}{\hat{e}(\textrm{covariates}_i)} - \frac{1}{n}\sum \frac{\hat{y}(\textrm{covariates}_i)*(1- A_i)}{1-\hat{e}(\textrm{covariates}_i)}
$$

Where $\hat{y}(\textrm{covariates}_i)$ are the predicted values of the outcome for each individual $i$, $A_i$ are the treatments received, and $\hat{e}(\textrm{covariates}_i)$ are the probabilities the individual received the treatment $A = 1$. By using both the outcome and treatment models, the researcher has ensured that this estimator will fail if either the model is wrong. Not only will it fail, but it will fail by the same amount as the individual estimators. This is very important. 

#### Failing the Same

For simplicity let's say IPW is 

$$
\frac{1}{n}\sum \frac{Y_i A_i}{\hat{e}(\textrm{covariates}_i)}  - \frac{1}{n}\sum \frac{Y_i (1-A_i)}{1-\hat{e}(\textrm{covariates}_i)}
$$

Where $Y_i$ are the actual outcome values. If the treatment model is correct this will produce a correct estimate of average causal effect.

Focus just on one side of the equation, and subtract the same side from the bad estimator above:

$$
\frac{1}{n}\sum \frac{Y_i A_i}{\hat{e}(\textrm{covariates}_i)} - \frac{\hat{y}(\textrm{covariates}_i)*A_i}{\hat{e}(\textrm{covariates}_i)}
$$

Our researcher, sees that if they have a correct outcome model then $Y_i A_i = \hat{y}(\textrm{covariates}_i)* A_i$ and so the whole thing would reduce zero. 

```{r}
part_estimates_1 <- t(get_dr_parts2_3(data, Y ~ A + Z + W + M, A ~ X))
rownames(part_estimates_1) <- c("Outcome Formula", "Exposure Formula", "Outcome Model Estimate", "IPW Estimate", "$\\frac{1}{n}\\sum \\frac{Y_i A_i}{\\hat{e}(\\textrm{covariates}_i)}$", "$-\\frac{1}{n}\\sum \\frac{\\hat{y}(\\textrm{covariates}_i)*A_i}{\\hat{e}(\\textrm{covariates}_i)}$","Difference")
knitr::kable(part_estimates_1, escape = FALSE, caption = "It does!")
```

## Works Cited {.appendix}

(in progress)

https://doi.org/10.1093/aje/kwq439
https://www.degruyter.com/document/doi/10.1515/jci-2018-0016/html?lang=en



## Code Appendix {.appendix}

### Simulating Data
```{r}
#| echo: true
n <- 100000
Z <- rnorm(n, 0, 1) # Z
W <- rbinom(n, 1, .5) # W

X <- rnorm(n, Z, 2)

log_odds_A <- .5 * Z + .5 * X
odds_A <- exp(log_odds_A)
p_A <- odds_A / (1 + odds_A)
A <- rbinom(n, 1, p_A) # A

M <- rnorm(n, 20 - 2, .5)

Y <- rnorm(n, A + W + 2 * Z + 0.05 * M, .25)

data <- data.frame(A = (A), Y = Y, Z = Z, M = M, W = (W), X = X)
```

### Perform IPW and Outcome Regression

```{r}
#| echo: true
get_normal_methods <- function(data, outcome_formula, exposure_formula) {
  outcome <- lm(outcome_formula)
  ps_model <- glm(exposure_formula, family = "binomial")
  
  
  data <- data %>%
  mutate(ps = predict(ps_model, newdata = data, type = "response")) %>%
  mutate(ipw = case_when(
            A == 1 ~ 1/ps,
            A == 0 ~ 1/(1-ps)
        ))
  
  example_ipw <- lm(Y ~ A, data = data, weights = ipw)
  # print(summary(example_ipw)$coefficients)
  # print(summary(outcome)$coefficients)
  mods <- t(c(outcome_formula,exposure_formula))
  output <- as.data.frame(cbind(mods, outcome$coefficients[2], 
                                example_ipw$coefficients[2]))
  names(output) <- c("Outcome Formula","Exposure Formula",
                     "Causal Effect Estimate from Outcome Model", 
                     "Causal Effect Estimate from Treatment Model")
  return(output)
}
```



