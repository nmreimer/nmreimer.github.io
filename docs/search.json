[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nathaniel Reimer",
    "section": "",
    "text": "he/him/his\nStudent @ Macalester College\n\n\nMacalester College in St. Paul MN  Major Data Science, Minor in Economics | Sept 2020 - May 2024"
  },
  {
    "objectID": "projects/californiaedu/school_insights.html#map-of-school-level-academic-achievement-categories-across-california-counties",
    "href": "projects/californiaedu/school_insights.html#map-of-school-level-academic-achievement-categories-across-california-counties",
    "title": "Beyond the Report Card: What are the insights at the school level that we can observe?",
    "section": "Map of School-level academic achievement categories across California counties",
    "text": "Map of School-level academic achievement categories across California counties"
  },
  {
    "objectID": "projects/californiaedu/school_insights.html#does-funding-impact-school-level-academic-achievement",
    "href": "projects/californiaedu/school_insights.html#does-funding-impact-school-level-academic-achievement",
    "title": "Beyond the Report Card: What are the insights at the school level that we can observe?",
    "section": "Does funding impact school-level academic achievement?",
    "text": "Does funding impact school-level academic achievement?\n\n\n\n\n\nOverall, regardless of area, higher per pupil funding is associated with lower growth scores. In California schools receive a base per-pupil grant dependent on the grades taught in the school. Schools receive supplemental funding based on the percent of students eligible for free and reduced lunch, the percent in the foster care system, and the percent that have limited English. We use a linear model of funding based solely on the percent of students eligible for free and reduced lunch to adjust funding. The negative relationship dissapears:\n\n\n\n\n\n\n\n\nSocioeconomic status, measured as the percent of students eligible for free and reduced lunch, significantly effects achievement. Additional funding received by schools with a high proportion of disadvantaged students does not affect achievement enough to offset the impact of socioeconomic status."
  },
  {
    "objectID": "projects/californiaedu/result.html",
    "href": "projects/californiaedu/result.html",
    "title": "Beyond the Report Card: Let’s discuss some results!",
    "section": "",
    "text": "Add result here\n\nGrowth score is pretty robust since there are no variables that actually predict it."
  },
  {
    "objectID": "projects/californiaedu/index.html",
    "href": "projects/californiaedu/index.html",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement using California as a Case Study",
    "section": "",
    "text": "Hi everyone, we are Thu, Nathaniel, and Jeremy, and welcome to our Capstone Project for STAT 456: Projects in Data Science. As you can tell from the title, we are interested in exploring the factors that impacting academic achievement, using California as a case study. Meet the team…\n\nYou can explore the diverse aspects of our project by navigating through various tabs on this website. Starting from our project’s inspiration, you can delve into the analysis of academic achievement insights at the county and school levels in California, learn about our model’s construction process, and discover some of the outcomes. Are you excited? Let’s get started!"
  },
  {
    "objectID": "projects/californiaedu/wideformatting.html",
    "href": "projects/californiaedu/wideformatting.html",
    "title": "Untitled",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(readxl)\nlibrary(MetBrewer)\nlibrary(sf)\n\nLinking to GEOS 3.10.2, GDAL 3.4.1, PROJ 8.2.1; sf_use_s2() is TRUE\n\nlibrary(rnaturalearth)"
  },
  {
    "objectID": "projects/californiaedu/wideformatting.html#data-sources",
    "href": "projects/californiaedu/wideformatting.html#data-sources",
    "title": "Untitled",
    "section": "Data Sources",
    "text": "Data Sources\n\nschool_data\nCodebook\n\nschool_data <- read.csv('AllDatasets/ca_education.csv') # dataset of public K-12 spending by school\n\nschool_data_clean <- school_data %>%\n  filter(flag_nerds == 'false') %>%\n  filter(flag_f33 != '1')\n\nschool_data identified by ncesid at school level – 10404\n\n\nela_metric_data\nCodebook\n\nela_metric_data <- read.csv('AllDatasets/ca_edu_metrics.csv') # 2022 Academic Indicator (English Language Arts/Literacy) Data File\n\nela_metric_data_clean <- ela_metric_data %>%\n  filter(cds > 0, rtype == 'S') %>% # school record\n  select(-color, -box) %>%\n  mutate(cds_standardized = as.character(paste0(\"0\", cds)))\n\ncolnames(ela_metric_data_clean) <- paste0(\"ela_data_\", colnames(ela_metric_data_clean))\nvaluecols<-names(ela_metric_data_clean)[10:21]\n\nela_wide <- ela_metric_data_clean %>% pivot_wider(names_from = ela_data_studentgroup, values_from = valuecols, names_sep = \"_\") %>% mutate(ela_data_cds = as.character(ela_data_cds))\n\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %>% select(valuecols)\n\n  # Now:\n  data %>% select(all_of(valuecols))\n\nSee <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.\n\n\nela_metric_data identified by cds at school level – 9845 AND student group – 165532\n\n\nela and math metrics\n\nela_mth_proficiency_ranges<-read.csv(\"AllDatasets/nathanieldata.csv\") %>% filter(GRADE == \"00\" & CATEGORY == \"ALL\") %>% mutate(NCESSCH = as.character(NCESSCH), NCESSCH = paste0(\"0\",NCESSCH))\n\n\n\nscience_metric_data\nCodebook\n\nscience_metric_data <- read.csv('AllDatasets/science_ca_assesment.csv', sep = \"^\")\n\nscience_metrics_clean <- science_metric_data %>%\n  mutate(cds = as.character(paste0(0, paste0(paste0(County.Code,District.Code),paste0(0,School.Code))))) %>% # add cds identifier\n  # mutate(cds_standardized = ifelse(nchar(cds) == 13, as.character(paste0(0,cds)), cds)) %>% # there are school codes missing the last 0, this fixes that to match other cds\n  filter(County.Code > 0, Type.ID == 07) %>%\n  select(-County.Code, -District.Code, -School.Code, -Filler) \n\n\nvaluecols <- c(names(science_metrics_clean)[8:25],names(science_metrics_clean)[4:5])\nscience_metrics_wide <- science_metrics_clean %>% pivot_wider(names_from = Grade, values_from = valuecols)\ncolnames(science_metrics_wide) <- paste0(\"science_data_\", colnames(science_metrics_wide))\n\ncolnames(science_metrics_clean) <- paste0(\"science_data_\", colnames(science_metrics_clean))\n\nscience_metrics_clean identified by cds_standardized at school level – 8819 AND Grade – 25298\n\n\nstanford_data and cov\nCodebook\nCovariate Codebook\n\nstanford_data <- read.csv('AllDatasets/seda_school_pool_gcs_4.1.csv')\nstanford_cov <- read.csv(\"AllDatasets/seda_cov_school_pool_4.1.csv\")\n\nstanford_cov <- stanford_cov %>% filter(stateabb == \"CA\")\n\nstanford_data_clean <- stanford_data %>% \n  filter(stateabb == 'CA') %>% \n  select(sedasch, sedaschname, fips, stateabb, subcat, subgroup, gradecenter, gap, contains(\"avg\"), -ends_with(\"se\")) %>%\n  mutate(standardized_school_id = paste0(\"0\", sedasch)) %>% # adding 0 in front of school id to match the format of the school dataset\n  left_join(stanford_cov)\n\nJoining with `by = join_by(sedasch, fips, stateabb)`\n\n\nstanford_data AND stanford_cov identify eachother by sedasch\nstanford_data AND stanford_cov identified by standardized_school_id – 8512\n\n\nca_school_details\n\nca_school_details <- read_excel(\"AllDatasets/ca_school_details.xlsx\") # CA schools metadata\n\nca_school_details_clean <- ca_school_details %>%\n  filter(StatusType == \"Active\") %>%\n  filter(School != \"No Data\") %>%\n  mutate(school_id = paste0(NCESDist, NCESSchool))\n\nca_school_details_clean identified by school_id – 10629\n\n\ngrowth_aggr\n\ngrowth_aggr <- read_excel(\"AllDatasets/growthaggr.xlsx\")\n\ngrowth_aggr_clean <- growth_aggr %>% filter(rtype == \"S\") %>% \n  filter(studentgroup == \"ALL\") %>%\n  pivot_wider(names_from = subject, values_from = c(n_growthscores, growthscore, decilerank))"
  },
  {
    "objectID": "projects/californiaedu/wideformatting.html#joining",
    "href": "projects/californiaedu/wideformatting.html#joining",
    "title": "Untitled",
    "section": "Joining",
    "text": "Joining\n\nwide_merged_data <- ca_school_details_clean %>% \n  left_join(school_data_clean, by=c('school_id'='ncesid')) %>%\n  left_join(science_metrics_wide, by = c(\"CDSCode\"=\"science_data_cds\")) %>%\n  left_join(ela_wide, by = c(\"CDSCode\"=\"ela_data_cds_standardized\")) %>% \n  left_join(stanford_data_clean, by=c('school_id'='standardized_school_id')) %>% \n  mutate(ncesid = paste0(NCESDist,NCESSchool)) %>%\n  left_join(growth_aggr_clean, by = c('CDSCode' = 'cds')) %>%\n  left_join(ela_mth_proficiency_ranges, by=c(\"ncesid\"=\"NCESSCH\"))\n\n\n# save(wide_merged_data, file=\"WideMergedData.RData\")\n\n# names(wide_merged_data)\n\n\n# length(unique(wide_merged_data$CDSCode)) #10629 unique schools from the metadata\n# length(unique(wide_merged_data$CDSCode[is.na(wide_merged_data$schoolname) == FALSE])) #4385 unique matched schools for Jeremy's california school data\n# length(unique(wide_merged_data$CDSCode[is.na(wide_merged_data$sedasch) == FALSE])) #7390 unique matched schools for Stanford data\n# length(unique(wide_merged_data$CDSCode[is.na(wide_merged_data$ela_data_cds) == FALSE])) #814 unique matched schools for ela data\n# length(unique(wide_merged_data$CDSCode[is.na(wide_merged_data$science_data_cds) == FALSE])) #495 unique matched schools for science data\n# length(unique(wide_merged_data$CDSCode[is.na(wide_merged_data$PE_data_cds) == FALSE])) #501 unique matched schools for pe data\n\n\n# wide_merged_data %>% filter(!is.na(urbanicity)) %>%\n#   ggplot(aes(x=as.numeric(pp_total_norm_NERDS), y=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)), color=urbanicity)) +\n#   geom_point(alpha = .1) + \n#   geom_smooth(method = lm) + \n#   facet_wrap(~urbanicity) + \n#   scale_x_continuous(limits = c(8000,18000)) + \n#   theme_nr()+\n#   labs(y=\"Grade Cohort Score\", x= \"Per Student Spending\") + guides(color=FALSE) +   geom_hline(yintercept = 0)\n\n\n# wide_merged_data %>% ggplot(aes(x=as.numeric(science_data_Percentage.Standard.Met.and.Above_13), y=(as.numeric(MTH_PCTPROF_max)))) +\n#   geom_point(alpha = .3) + \n#   geom_smooth(color=\"grey\",method=lm) + theme_nr() + labs(x = \"Percent Proficient on State Science Test\", y=\"Maximum* Percent Proficient on NAEP Math Test\", caption = \"*True value is hidden to protect student privacy at smaller schools\")\n# \n# wide_merged_data %>%\n#   ggplot(aes(x=as.numeric(perhsp), y=(as.numeric(perfrl)))) +\n#   geom_point(alpha = .05) + \n#   geom_smooth(color=\"black\") + theme_nr() + labs(x = \"Percent Hispanic\", y=\"Percent Eligible fro Free and Reduced Lunch\")\n# \n# \n# wide_merged_data %>% filter(!is.na(urbanicity)) %>%\n#   ggplot(aes(x=as.numeric(perfrl),y=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)),color=State)) +\n#   geom_point(alpha = .05) +\n#   geom_smooth(method=lm)+\n#   guides(color=FALSE) + \n#   theme_nr()+\n#   labs(x=\"Percent Eligible for Free and Reduced Lunch\", y=\"Grade Cohort Score\")+\n#   geom_hline(yintercept = 0)\n# \n# wide_merged_data %>% filter(!is.na(urbanicity)) %>%\n#   ggplot(aes(x=as.numeric(perhsp),y=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)),color=State)) +\n#   geom_point(alpha = .05) +\n#   geom_smooth()+\n#   guides(color=FALSE) + \n#   theme_nr()+\n#   labs(x=\"Percent Hispanic\", y=\"Grade Cohort Score\")+\n#   geom_hline(yintercept = 0)\n\n\n# counties <- st_as_sf(maps::map(\"county\", plot = FALSE, fill = TRUE))\n# counties <- subset(counties, grepl(\"california\", counties$ID))\n# world <- ne_countries(scale = \"medium\", returnclass = \"sf\")\n# \n# ggplot(data = world) +\n#   geom_sf(data = counties, fill='#f0f1f9') + \n#   geom_point(data = (wide_merged_data%>%filter(!is.na(gradecenter)&!is.na(gcs_mn_avg_ol))) , aes(x=as.numeric(Longitude),y=as.numeric(Latitude),color=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)),size=as.numeric(ncesenroll)), alpha =.5) +\n#   theme_classic() +\n#   scale_color_met_c(\"Benedictus\",direction = 1) +\n#   scale_size_area(max_size = 2) + theme_nr() +\n#   labs(x=\"Longitude\",y=\"Latitude\",color=\"Grade Cohort Score\",title = \"California School Location and Academic\\nPerformance\")+guides(size=FALSE)+theme(legend.position = c(.8,.8))\n# \n# # ----------------------------------------------------\n# ggplot(data = world) +\n#   geom_sf(data = counties, fill='#f0f1f9') + \n#   geom_point(data = (wide_merged_data%>%filter(!is.na(gradecenter)&!is.na(gcs_mn_avg_ol))) , aes(x=as.numeric(Longitude),y=as.numeric(Latitude),color=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)),size=as.numeric(ncesenroll)), alpha =.5) +\n#   theme_classic() +\n#   scale_color_met_c(\"Benedictus\",direction = 1) +\n#   scale_size_area(max_size = 7) + theme_nr() +\n#   labs(x=\"Longitude\",y=\"Latitude\",color=\"Grade Cohort Score\",title = \"Bay Area Academic Performance\")+guides(size=FALSE)+theme(legend.position = c(.28,.3)) +\n#   coord_sf(xlim=c(-121.25,-123.5), ylim= c(36.75,38.75))\n# \n# # -------------------------------------------------\n# ggplot(data = world) +\n#   geom_sf(data = counties, fill='#f0f1f9') + \n#   geom_point(data = (wide_merged_data%>%filter(!is.na(gradecenter)&!is.na(gcs_mn_avg_ol))) , aes(x=as.numeric(Longitude),y=as.numeric(Latitude),color=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)),size=as.numeric(ncesenroll)), alpha =.5) +\n#   theme_classic() +\n#   scale_color_met_c(\"Benedictus\",direction = 1) +\n#   scale_size_area(max_size = 2) + theme_nr() +\n#   labs(x=\"Longitude\",y=\"Latitude\",color=\"Grade Cohort Score\",title = \"Los Angeles and San Diego Academic\\nPerformance\")+guides(size=FALSE)+theme(legend.position = c(.3,.3)) +\n#   coord_sf(xlim=c(-117,-120), ylim= c(32,35))\n\n\n# ggplot(data = world) +\n#   geom_sf(data = counties, fill='#f0f1f9') + \n#   geom_point(data =((wide_merged_data %>% filter(!is.na(pp_total_norm_NERDS) & as.numeric(pp_total_norm_NERDS) > 7000 & as.numeric(pp_total_norm_NERDS) < 25000))), aes(x=as.numeric(Longitude),y=as.numeric(Latitude),color=as.numeric(pp_total_norm_NERDS),size=as.numeric(ncesenroll)), alpha =.25) +\n#   theme_classic() +\n#   scale_color_met_c(\"Benedictus\",direction = 1) +\n#   scale_size_area(max_size = 2) + theme_nr() +\n#   labs(x=\"Longitude\",y=\"Latitude\",color=\"Per Student Spending\",title = \"California School Location and Per Student\\nSpending\")+guides(size=FALSE)+theme(legend.position = c(.8,.8))"
  },
  {
    "objectID": "projects/californiaedu/IntermediateNarrative.html#analyses-with-a-short-description-of-results",
    "href": "projects/californiaedu/IntermediateNarrative.html#analyses-with-a-short-description-of-results",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement",
    "section": "Analyses with a short description of results",
    "text": "Analyses with a short description of results\nThu’s results\nThis map shows the deviation in SEDA scores from the national standard for each county, providing a broad overview of academic achievement levels in Californian counties. Overall, areas in cities or richer suburbs (Silicon Valley, Los Angeles, San Diego) have higher academic performance than national average, shown through brigher colors (yellow and green). On the other hand, areas with fewer schools (e.g. Inyo – a national forest area) have lower academic performance than national average, denoted by darker (blue and purple) colors.\n\n\n\n\n\n\n\n\n\nJeremy’s results\nWe examined solely the schools for which we have complete data available, i.e., the schools in the intersection of our datasets. Among these schools, across all metrics, an increase in per-pupil government spending (both state and federal) showed a negative correlation with performance. At first glance, the outcomes appear to be linked to the increase in per-pupil spending when there is a significant percentage of students who are English learners, in the foster care system, or eligible for free/reduced lunch.\n\n\n\nNathaniel’s results\n\n\n\nSpending per student varies significantly across the state. We thought that this might explain some of the funding-achievement issue we had come across. After seeing that the same negative relationship existed to some degree in each locale we decided that location, or at least type of area, was not the factor we were looking for. It is also worth noting that the ‘Rural’ and ‘Town’ areas seem to be under performing for some reason.\n\n\n\n\n\n\n\n\n\nWe understand that funding for schools in California is based in part on the percent of students eligible for free and reduced lunch, the percent in the foster care system, and the percent that have limited English. So we decided to fit some simple models of funding and these variables. We then adjusted per student spending based on the simplest model: funding ~ free and reduced lunch. This flattened the relationship between funding and achievement and flipped the relationship between percent Hispanic and spending.\n\n\n\nThe flattened relationship persists in each area.\nThe percent of students eligible for free and reduced lunch directly influences spending in the state of California. However, in wealthy localities with strong property tax bases, funding often exceeds the amount allotted by the state of California. These areas also have a lower percent of students eligible for free and reduced lunch. So our model is not looking directly at the supplemental grant received for the percent of students eligible for free and reduced lunch. Nevertheless we think it provides a more accurate picture than the raw spending metric.\nThe adjustment is very very rudimentary and would benefit from more investigation. We could probably use school location in conjunction with census data to get some picture of property taxes and local funding, but variation in local tax and funding structures could make this difficult."
  },
  {
    "objectID": "projects/californiaedu/IntermediateNarrative.html#project-plan",
    "href": "projects/californiaedu/IntermediateNarrative.html#project-plan",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement",
    "section": "Project plan",
    "text": "Project plan\nMoving forward, we would love to:\n\nExpand further on funding metrics and explore ways to adjust them in a way that they don’t give a false picture when taken out of context (Nathaniel has put in some work in this regard and we have a plan to accomplish this)\nIdentify more potential metrics through bivariate visualizations and adjust them so that we can put all of them together into a model that explains different education proxies\nTell a better story with missing data (for example, why certain data is missing, where is it from, where does the data in our different datasets overlap and where does it not, are there trends here or not)"
  },
  {
    "objectID": "projects/californiaedu/IntermediateNarrative.html#summary-of-contributions",
    "href": "projects/californiaedu/IntermediateNarrative.html#summary-of-contributions",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement",
    "section": "Summary of contributions",
    "text": "Summary of contributions\nThu, Nathaniel, and Jeremy all contribute equally to this checkpoint. Specifically:\n\nThu was responsible for cleaning and standardizing school identifiers to merge all datasets together in long format. She also cleaned the data for and visualized the general map displaying the deviation in SEDA scores from the national standard for each county, which provides a broad overview of academic achievement levels in Californian counties. Lastly, she consolidated the narration for the results and also this write-up using all of Jeremy and Nathaniel’s inputs, and organized the slides for the intermediate presentation.\nNathaniel was responsible for cleaning and merging the dataset into a wide format, as well as creating several visualizations that aided us in developing a narrative about the funding for this intermediate visualization. Additionally, he proposed a new concept for modeling an adjusted funding metric, which will provide us with a more comprehensive understanding of the correlation between funding and academic achievement at the school level.\nJeremy was responsible for gathering and aggregating some of the initial datasets that Thu then later merged with other datasets. He also conducted various analyses to compare the trend of different educational proxies as school funding increases. Due to his extensive knowledge about California, he is the primary result interpreter of the team. This enables us to contextualize the outcomes and generate ideas for future steps. Furthermore, he played a role in exploring different potential variables by cleaning the data for and visualizing various bivariate graphs."
  },
  {
    "objectID": "projects/californiaedu/county_insights.html",
    "href": "projects/californiaedu/county_insights.html",
    "title": "Beyond the Report Card: What are the insights at the county level that we can observe?",
    "section": "",
    "text": "An overall look at Academic Achievement across Californian counties\nIn this analysis, we define academic achievement as the difference between the Grade Cohort Standardize (GCS) Scores and NAEP standard. As a reminder of the interpretation for GCS scores, we can look at this example again: If 4th-grade students at the school of interest have a GCS value of 5.03, these students’ scores indicate a level equivalent to 5th-grade, which is about one grade level higher than the national average (the reference group) in math.\nTo create this map, we calculated the difference in GCS scores from the grade levels for each grade-school cohort, then aggregated them by the Californian counties. We divided the score differences into 3 categories: 1-2 years behind, Less than 1 year behind, and Less than 1 year ahead.\n\n\n\n\n\n\n\n\n\n Looking at this map, it is clear that there is a significant difference in academic performance across various regions in California. The Bay Area and Orange County appear to outperform other counties, along with affluent tourist counties like Placer and El Dorado. However, for the remaining counties, while approximately half of them exhibit students with academic performance on par with the national average, a significant proportion of counties have students lagging behind by 1-2 years.\nWe recognize that there may be a huge wealth disparity among diverse communities in California. Therefore, our next step is to delve deeper into the social factors that may be contributing to what we’re observing on this map.\n\n\nFurther exploration into the county-level math and reasoning language arts (RLA) achievement of different student groups\nIndeed, according to Cano and Hong, California faces challenging income disparities and intricate demographics that extend beyond its public education system. Since 2008, California has implemented extensive reforms aimed at allocating more resources to high-needs students and addressing educational disparities, with some success. However, despite these efforts, Black, Latino, and low-income students continue to significantly underperform compared to Asian American, white, and wealthier students in both math and reading proficiency (Ricardo Cano 2022). A UCLA research shows that Californian schools are the most segregated for Latinos, with 58% attending schools that are highly segregated. Additionally, The study also revealed that over 50% of Black students in California are concentrated in only 25 out of 1,000 school districts (Erica Frankenberg 2019).\nSince we’re interested in how different socioeconomic backgrounds might influence education achievement, we looked into how students classified as economically disadvantaged according to the Californian standard perform compared to those in the non-economically disadvantaged group in terms of GCS scores. By definition, students are typically considered economically disadvantaged if they come from a low-income household or meet other criteria for poverty, such as eligibility for free or reduced-price meals, homelessness, or foster care. The criteria for California can be found here. The GCS score differences are broken down into 6 categories, ranging from being 2+ years behind to 2+ years ahead compared to the NAEP standard. The GCS categories are also divided into two disciplines, i.e. math and RLA for both economically disadvantaged and non-economically disadvantaged groups.\n\n\n\n\n\n\n\n\n\n\n\n\n Although it is intuitive that economically disadvantaged students perform worse than their non-economically disadvantaged peers, it is still not at all less shocking when we looked at this map for the first time. The general trend shows that at county level, there is almost no overlapping in academic achievement between economically disadvantaged and non-economically disadvantaged student groups, for both math and RLA. Specifically, while the economically disadvantaged group is lagging behind by 1 to 2+ years behind the national standard, the more privileged group performs much better, having a performance gap of less than 1 year to being 2+ years ahead of the national standard.\n\n\n\n\n\nReferences\n\nErica Frankenberg, Jennifer B. Ayscue, Jongyeon Ee. 2019. “Harming Our Common Future: America’s Segregated Schools 65 Years aFter Brown.” The Civil Rights Project. www.civilrightsproject.ucla.edu.\n\n\nRicardo Cano, Joe Hong. 2022. “Mind the Achievement Gap: California’s Disparities in Education, Explained.” Calmatters. https://calmatters.org/explainers/achievement-gap-california-explainer-schools-education-disparities-explained/."
  },
  {
    "objectID": "projects/californiaedu/data.html",
    "href": "projects/californiaedu/data.html",
    "title": "Beyond the Report Card: Our Motivation",
    "section": "",
    "text": "A sneak peek into the data\nThe data set we have includes a range of school-related variables such as location details, funding, and aggregated scores in various subjects. Specifically, the score variables cover the general grade-cohort-standardized achievement score, as well as scores in reading, science, and physical education.\nWe aggregate our dataset from 5 different datasets. We use data from The California Department of Education, Georgetown University, and the Educational Opportunity Project at Stanford University.\nScience Testing Data Codebook\nOur science test data is from the California Department of Education, specifically, from the 2021-2022 school year. It is from the California Science Test, in which there are three different categories, namely Life sciences, Physical sciences, and Earth and Space sciences.\nEnglish Testing Data Codebook\nThe data we have for English Language Arts / Literature is also from the California Department of Education, specifically from 2022. It tells us for each student group within each school their level of proficiency.\nPhysical Education Data Codebook\nOur PE data comes from the California Department Education from the 2018-2019 school year. It has 7 different types of exercises and each school’s grade’s proficiency on each type of exercise.\nSchool Funding Data Codebook\nOur school funding data is aggregated 2019-2020 data from different federal and state sources. It is compiled into the dataset we are using by Georgetown University researchers. It has information about funding going to a school from the state, local, and federal governments, as well as metadata about the school such as enrollment, as well as data about the income levels of the students at the school.\nThe Educational Opportunity Project at Stanford University (SEDA) Codebook Covariate Codebook\nThe SEDA dataset contains school-level standardized academic achievement data across all Californian schools. These achievement scores are graded and cohort standardized against the NAEP standard, indicating whether the students in a particular school and grade level are meeting the national standard for their grade. For instance, if a school’s 4th-grade students score 3.5, it indicates that they are lagging behind the national standard by 0.5 points. The achievement estimates are calculated using Ordinary Least Square (OLS) and Empirical Bayesian (EB) techniques.\nSchool Details Codebook\nThis contains metadata on 10629 California Schools, including both the nationally used school identifier, or NCES ID, and the California CDS code. We use this to join our data from our different sources. This dataset also contains the longitude and latitude of the schools which has been very useful for EDA so far.\nAggregated Growth Codebook\nThis contains data on Mathematics and English Language Arts growth by school and student group for California Schools. California developed the growth model to show how much student’s scores were growing from year to year.\n\n\nGoing into details regarding the metrics considered in this analysis\nIn this analysis, we focused on using Grade Cohort Standardized scores, which is a metric created by the SEDA project, and growth score (?), both at county- and school-level. Additionally, we also considered school-level test scores in various subjects, including English, Science, and Physical Education (PE).\nGrade Cohort Standardized (GCS) scores: According to the Stanford Codebook, “[t]he GCS scale standardizes the unit means relative to the average difference in NAEP scores between students one grade level apart” (“Methods: How SEDA Produced Estimates of Student Performance That Are Comparable Across Places, Grades, and Years.” 2022). NAEP stands for National Assessment of Educational Progress, which is an assessment program in the United States that aiming to assess and measure the academic performance of students across different subjects and grades, generally referred to as the Nation’s Report Card (“About NAEP” 2023). The GCS scale allows users to understand one unit as being equivalent to one grade level. In Grade 3, the national average performance is 3 units, while in Grade 4, it is 4 units, and so on. Here are two brief examples to interpreting GCS values: If 4th-grade students at the school of interest have a GCS value of 5.03, these students’ scores indicate a level equivalent to 5th-grade, which is about one grade level higher than the national average (the reference group) in math. Vice versa, if 3rd-grade students at the school of interest have a GCS value of 2.39, these students’ reading scores indicate a level about half a grade level lower than the national average for 3rd-grade students (“Methods: How SEDA Produced Estimates of Student Performance That Are Comparable Across Places, Grades, and Years.” 2022). GCS values are aggregated over the years of 2009, 2011, 2013, and 2015, and and are collected at school- and county-level.\nGrowth score: Aggregate growth scores are available for English and Mathematics broken down by school and student group. They measure how close the students growth is to their expected growth. A growth score of 100 indicates students are meeting expected growth; below 100 indicates growth below expectations; and above 100 indicates growth above expectations. Since the scores measure growth they are based on multiple years of testing data: the 2016-17, 2017-18, and 2018-19 school years. Pandemic disruption means that the current growth scores are not actionable. Growth scores will be released again in 2024. Nevertheless, the scores are still useful for our analysis.\nSubject-specific test scores: We obtained data on test scores for various subjects, including English, Science, and PE. During our initial investigation, after joining these test score datasets with the SEDA and funding data, we saw that the test scores only matched up with a very small percentage of schools in our dataset. Further investigation shows that the test scores are only collected in the East Bay area and various northern CA counties. Since it is desirable to have a full coverage of state scores for the subsequent analysis and modeling process, we decided not to use the subject-specific test score datasets.\nWe can add that interesting viz here – what interesting viz?\n\n\n\n\n\nReferences\n\n“About NAEP.” 2023. National Assessment Governing Board. https://www.nagb.gov/naep/about-naep.html.\n\n\n“Methods: How SEDA Produced Estimates of Student Performance That Are Comparable Across Places, Grades, and Years.” 2022. The Educational Opportunity Project at Stanford University. https://edopportunity.org/methods/."
  },
  {
    "objectID": "projects/californiaedu/motivation.html",
    "href": "projects/californiaedu/motivation.html",
    "title": "Beyond the Report Card: Our Motivation",
    "section": "",
    "text": "A change in direction\nInitially, our focus was on the correlation between affordable housing and educational achievement. However, during the process of selecting appropriate educational proxies, we found ourselves delving into the factors behind the measurements of these proxies. As a result, we decided to seek the guidance of Professor Lesley Lavery, who specializes in public policies in education. We hope to gain a better understanding of the educational proxies currently in use and to investigate whether there are additional factors that impact educational outcomes and potentially render the current proxies interchangeable or distinct from other measures.\n\n\nPrevious literature\nThere are several reasons why education proxies differ, including the influence of socioeconomic status, the difficulty in standardizing scores across schools, and variations in school budgets. While % of high school graduates may be a more robust metric to estimate the education achievement level in different areas, it is harder to standardize score-related metrics due to differences in grading scales and the difficulty of obtaining student-level data (“Expert Interview with Lesley Lavery at Macalester College on 8 March 2023” 2023).\nAdditionally, due to the diverse student body in the US, it is difficult to identify specific teaching approaches that are effective for particular groups of students. The Measures of Effective Teaching Project by the Gates Foundation aimed to establish innovative teacher-evaluation systems incorporating classroom observation rubrics and student achievement growth measures. Although the Gates Foundation allocated $600 million towards this initiative, it turned out to be a challenging task, particularly in identifying effective teaching elements that positively influence students’ academic performance. Consequently, this research heightened our curiosity in examining other factors that contribute to students’ achievements beyond teaching approaches (Will 2018).\nAnother discourse associated with academic achievement is funding allocation and whether spending more helps improve academic achievement. (to be added more)\n\n\nWhy California?\nVarious socioeconomic factors can affect students’ academic performance, beyond just teaching methods. Given that California is a diverse state with people from different socioeconomic backgrounds, it presents an intriguing case study for our research topic, which focuses on exploring the socioeconomic factors that influence students’ grades.\n\n\n\n\n\nReferences\n\n“Expert Interview with Lesley Lavery at Macalester College on 8 March 2023.” 2023.\n\n\nWill, Madeline. 2018. “‘An Expensive Experiment’: Gates Teacher-Effectiveness Program Shows No Gains for Students.” EducationWeek. https://www.edweek.org/teaching-learning/an-expensive-experiment-gates-teacher-effectiveness-program-shows-no-gains-for-students/2018/06."
  },
  {
    "objectID": "projects/californiaedu/model.html",
    "href": "projects/californiaedu/model.html",
    "title": "Beyond the Report Card: What are the significant predictors?",
    "section": "",
    "text": "LASSO code"
  },
  {
    "objectID": "projects/asteroids/index.html",
    "href": "projects/asteroids/index.html",
    "title": "Asteroid Value Analysis",
    "section": "",
    "text": "A report that visualizes the location, size, composition, and value of asteroids in the Asterank dataset. Created in collaboration with Aaliyah Dick and Courtney Brown."
  },
  {
    "objectID": "projects/asteroids/index.html#background",
    "href": "projects/asteroids/index.html#background",
    "title": "Asteroid Value Analysis",
    "section": "Background",
    "text": "Background\nAfter the Moon Landing in 1969, interest in the universe beyond Earth surged and one of many questions raised was that of asteroid mining. NASA’s Jet Propulsion Laboratory maintains a database called the Small Bodies Database (SBDB) containing a record of small Solar System bodies, which includes any celestial body in our Solar System other than planets and natural satellites (e.g. moons). In 2012, a new database called Asterank was created using the SBDB, among other sources. New variables include the spectral type, value, and profit of each asteroid, which are critical for mining. Most of the following analysis is based on a subset of only asteroids with defined spectral types in Asterank’s data."
  },
  {
    "objectID": "projects/asteroids/index.html#definitions-and-setup",
    "href": "projects/asteroids/index.html#definitions-and-setup",
    "title": "Asteroid Value Analysis",
    "section": "Definitions and Setup",
    "text": "Definitions and Setup\n\nAsteroid\nAsteroids are small rocky, metallic, or icy bodies with no atmosphere orbiting the Sun.\n\n\nAU\nAn Astronomical Unit (AU) is a unit of length roughly equal to the distance from the Earth to the Sun and is about 150 million kilometers (93 million miles).\n\n\nComposition\nAsteroids fall into 3 different composition classes: C-type, S-type, and M-type. C-type, or chondrite, asteroids are the most common and consist of clay and silicate rocks. S-type, or “stony”, asteroids are made of silicate materials and nickel-iron. M-type, or metallic, asteroids have varied composition depending on how far from the Sun they formed. Composition can be estimated using spectral data.\n\n\nSpectral Type\n\nVariable Name: spec_B\nAsteroids are typed based on their emission spectrum, albedo, and color. See https://en.wikipedia.org/wiki/Asteroid_spectral_types for list of spectral types. Essentially, this is based on how objects reflect and absorb different wavelengths of light.\n\n\n\nDelta-v\n\nVariable Name: dv\nDelta-v is used to calculate the accessibility, with lower values indicating easier access. Delta-v is, more specifically, the change in velocity (measured in km/s) required of mining spacecraft in order to make contact with the asteroid. Most NEAs require a delta-v around 6-8 km/s and very few asteroids have a delta-v smaller than 4 km/s.\n\n\n\nMain Belt\nThe main belt, also called the asteroid belt or main asteroid belt, is located between Mars and Jupiter contains many of the asteroids in the Solar System, second only to the Kuiper Belt. It is believed that the main belt have been a planet if not for the gravitational pull of Jupiter in the early Solar System.\n\n\nMOID\n\nVariable Name: moid\nMinimum orbit intersection distance, or MOID, is used to assess potential close approaches and collision risks of astronomical objects. A smaller MOID value, and thus a smaller minimum distance, indicates a higher level of risk (but NOT inevitability). MOID is often measured in AU (defined below) or ld (the distance between the moon an Earth).\n\n\n\nNEAs\nNEA is an abbreviation of Near-Earth Asteroid (q < 1.3 AU). There are four groups of NEAs (Atira, Aten, Apollo, & Amor) based on perihelion distance (q), aphelion distance (Q) and their semi-major axes (a).\n\n\nPerihelion\n\nVariable Name: q (AU)\nThe perihelion is the point in orbit closest to the sun.\n\n\n\nPHAs\nPHA is an abbreviation of Potentially Hazardous Asteroid. These are asteroids that have been determined to be at risk of making a threatening approach to the Earth, more specifically asteroids with MOID ≤ 0.05 AU and H ≤ 22.0.\n\n\nSPK-ID\nThe SPK-ID of an asteroid is its identifier in the JPL Small Body Database.\n\n\nHow Asterank Calculates Value and Profit\nWe need to understand how Asterank estimates price and profit before we can do any analysis.\nSince Asterank’s code is available publicly on github we can analyze exactly how it arrives at its predictions for value and profit. Asterank first assigns composition estimates to asteroids based on their spectral type. For example, a type Cg asteroid is .2% water and .166% iron (and other elements). It then uses either estimates of mass in existing literature or estimates of diameter to calculate how much of each element is in each asteroid by weight. Mapping these to material values in $/kg, Asterank calculates the total value for each asteroid. Using calculated delta-v values Asterank estimate the cost of getting to an asteroid and bringing it back to lunar orbit. Profit is calculated with price and cost.\nSide note: Objects would be placed in lunar orbit so that there would be no chance of them impacting Earth.\nThe final value is a product of estimates on estimates on estimates. For the most part, We only have calculated values for asteroids with spectral data. These account for around 5,200 of the nearly 800,000 objects in Asterank’s data. And only 996 have a price greater than 1 cent. Aside from simply unavailable spectral data the biggest issue is estimating composition. There have only been a couple of successful asteroid sample return missions and even less is known about the interior of these objects, not to mention the composition variation from asteroid to asteroid that Asterank cannot account for."
  },
  {
    "objectID": "projects/asteroids/index.html#analysis",
    "href": "projects/asteroids/index.html#analysis",
    "title": "Asteroid Value Analysis",
    "section": "Analysis",
    "text": "Analysis\n\nLocating Value and Profit\n\n\n\n\n\n\n\n\n\nLet’s start by taking a look at where in the solar system asteroids are along with their value. The many parameters needed to define an objects orbit in the solar system make visualizing location complex. We simplify this by defining location as the distance to the sun when the object is closest to the sun. This is called the perihelion and is measured in Astronomical units (AU) where 1 AU is the approximate distance from the earth to the sun. An object with a highly elliptical orbit which passes though Earth’s orbit at its closest point and Jupiter’s orbit at its furthest point would appear on this plot at Earth. For these highly elliptical objects this visualization clearly does not work well. The eccentricity of an orbit is a measure of how elliptical the orbit is. Lower eccentricities indicate a more circular orbit. High eccentricity in an orbit means that there is a wider range (a.k.a. less consistency) of distance between the asteroid and the Sun. For reference, Earth has an eccentricity of 0.016 and Pluto has an eccentricity of 0.25. The median eccentricity of objects in the full Asterank data is 0.1504736. So it is probably okay just to use the closest point to the sun for our purposes but a more scientific approach would need more orbit parameters.\nAsteroids in our data are the most dense just past the orbit of Mars before Jupiter. This area is the asteroid belt. Asteroids that travel closer to the sun than Mars does have typical values less than one hundred trillion and often less than one trillion (note that the y-axis has been log transformed). In the asteroid belt and beyond, asteroids have calculated values far beyond one trillion, going into quadrillions and quintillions. The asteroids in these regions of space are orders of magnitude apart in terms of price. The size of this difference allows us to be confident in the relationship even if Asterank’s predictions are not exceedingly accurate.\n\n\n\n\n\n\nLooking at individual asteroids with spectral type we see that high profit asteroids tend to be type C and not very close to earth. There are a number of lower profit X type asteroids closer to Earth.\nSo, price is not everything, it costs an incredible amount to get to asteroids and bring them back to earth. Just because an asteroid has a high value does not mean it will be profitable or feasible to mine.\n\n\nDelta-V and Accessibility\nOne priority in determining asteroid profit is the ease of access. Delta-v (Δv) is used to calculate the accessibility, with lower values indicating easier access. Specifically, Δv is the change in velocity (measured in km/s) required of mining spacecraft in order to make contact with the asteroid. But we cannot decide what to mine based on Δv alone. The asteroids named “2018 AV2” and “2009 HC82”, for example, have the smallest and largest Δvs in the dataset (3.74 and 51.19 km/s respectively) but have estimated prices of $0.\n\n\n\n\n\n\n\n\n\n\nThe asteroids in this data subset are massive. In 2012 scientists from NASA and a variety of educational institutions wrote a report on the feasibility of asteroid retrieval. They came up with a plan using current technology and technology in development to bring a 7-meter, 500 ton asteroid into lunar orbit. They estimated the cost at more than 2 billion dollars. In the plot above a red line is placed at 7 meters. None of the asteroids in the subset of data we are working with that have defined diameters fall below this line. It is not currently feasible to bring any of them to the moon.\n\n\n\n\n\n\n\n\n\nThis paper did identify several potential candidates for capture and return. And, for NASA, the real profitability is in science and having access to materials in space. 500 tons of asteroid are 500 tons of material that do not need to be launched into space with expensive rockets.\n\n\n\n\n\n\n\nAsterank still sees these asteroids as quite profitable, if not currently feasible. The graph of estimated profit is strikingly similar to the graph of price. Even considering the higher cost of getting to the main belt it is still worthwhile. Expenses are considerable though, while the profit plot has a similar shape it is shifted down considerably. For the median asteroid in our data, expenses eat up 92% of the asteroids value.\nAll of this is hypothetical. There is not country or company that has or is about to capture, return, and mine an asteroid. And certainly not any of the large, high value asteroids in the main belt. Estimates for price and composition are just estimates and more research is needed to clarify them. Right now the focus is on gathering information on asteroids and Asterank is a great tool for generating interest and support for that research.\nNotably, NASA’s OSIRIS-REx mission is on track to return an asteroid sample to Earth in 2023. This, like meteorite composition studies, can be used to better link spectral and composition data."
  },
  {
    "objectID": "projects/asteroids/index.html#resources",
    "href": "projects/asteroids/index.html#resources",
    "title": "Asteroid Value Analysis",
    "section": "Resources",
    "text": "Resources\nAsterank\nAsteroids - Wikipedia\nBasic Asteroid Info - NASA\nObject Classifications - Planetary Data System\nSpectral Types - Wikipedia\nAsteroid Retrieval Feasibility Study\nOSIRIS-REx"
  },
  {
    "objectID": "projects/asteroids/index.html#appendix",
    "href": "projects/asteroids/index.html#appendix",
    "title": "Asteroid Value Analysis",
    "section": "Appendix",
    "text": "Appendix"
  },
  {
    "objectID": "projects/doublerobust/index.html#sources",
    "href": "projects/doublerobust/index.html#sources",
    "title": "Doubly Robust Estimators",
    "section": "Sources",
    "text": "Sources\n\n“Doubly Robust Estimation of Causal Effects” by Funk et al. and “A Falsifiability Characterization of Double Robustness Through Logical Operators” by Frangakis were used heavily in this project. My goal in this project was essentially to create an explanation of double robustness that combined Frangakis’ logical framework with the more numerical and simulation-based approach of the Funk paper.\nhttps://doi.org/10.1093/aje/kwq439\nhttps://www.degruyter.com/document/doi/10.1515/jci-2018-0016/html?lang=en"
  },
  {
    "objectID": "projects/doublerobust/index.html#code-appendix",
    "href": "projects/doublerobust/index.html#code-appendix",
    "title": "Doubly Robust Estimators",
    "section": "Code Appendix",
    "text": "Code Appendix\n\n\nSimulating Data\n\nset.seed(7)\nn <- 100000\nZ <- rnorm(n, 1, 2) # Z\n\nW <- rbinom(n, 1, .5) # W\n\nX <- rnorm(n, 2*W, 2) # X\n\nM <- rnorm(n, 20, 1) # M\n\nN <- rnorm(n, 10, 2) # N\n\nlog_odds_A <- .25 * Z + .5 * X + .1 * N\nodds_A <- exp(log_odds_A)\np_A <- odds_A / (1 + odds_A)\nA <- rbinom(n, 1, p_A) # A\n\n\n\nY <- rnorm(n, A + W + 2 * Z + 0.05 * M + rnorm(n, 2, 1), .25) # Y\n\ndata <- data.frame(A = (A), Y = Y, Z = Z, M = M, W = (W), X = X)\n\n\n\nFunction for Normal Methods\n\nget_normal_methods <- function(data, outcome_formula, exposure_formula) {\n  outcome <- lm(outcome_formula)\n  ps_model <- glm(exposure_formula, family = \"binomial\")\n  \n  \n  data <- data %>%\n  mutate(ps = predict(ps_model, newdata = data, type = \"response\")) %>%\n  mutate(ipw = case_when(\n            A == 1 ~ 1/ps,\n            A == 0 ~ 1/(1-ps)\n        ))\n  \n  example_ipw <- lm(Y ~ A, data = data, weights = ipw)\n  # print(summary(example_ipw)$coefficients)\n  # print(summary(outcome)$coefficients)\n  mods <- t(c(outcome_formula,exposure_formula))\n  output <- as.data.frame(cbind(mods, outcome$coefficients[2], example_ipw$coefficients[2]))\n  names(output) <- c(\"Outcome Formula\",\"Exposure Formula\",\"Causal Effect Estimate from Outcome Model\", \"Causal Effect Estimate from Treatment Model\")\n  return(output)\n}\n\n\n\nFunction for Two Parts of DR Estimator\n\nget_dr_parts2_3 <- function(data, outcome_formula, exposure_formula) {\n  outcome <- lm(outcome_formula)\n  ps_model <- glm(exposure_formula, family = \"binomial\")\n  \n  forceA0 <- data %>% mutate(A = 0)\n  forceA1 <- data %>% mutate(A = 1)\n\n  predA0 <- predict(outcome, newdata = forceA0)\n  predA1 <- predict(outcome, newdata = forceA1)\n\n  data <- data %>%\n  mutate(ps = predict(ps_model, newdata = data, type = \"response\")) %>%\n  mutate(ipw = case_when(\n            A == 1 ~ 1/ps,\n            A == 0 ~ 1/(1-ps)\n        ))\n  part1 <- predA1\n  part2 <- ((data$Y * data$A) / (data$ps))\n  part3 <- -((predA1 * data$A) / data$ps)\n\n\n  example_ipw <- lm(Y ~ A, data = data, weights = ipw)\n\n  mods <- t(c(outcome_formula,exposure_formula))\n  output <- as.data.frame(cbind(mods, outcome$coefficients[2], example_ipw$coefficients[2], mean(part2), mean(-part3), mean(part2+part3)))\n  names(output) <- c(\"Outcome Formula\",\"Exposure Formula\", \"Outcome Model Estimate\", \"IPW Estimate\", \"$B$\", \"$C$\", \"D\")\n  return(output)\n}\n\n\n\nFunction for All Parts of DR Estimator\n\nget_dr_parts <- function(data, outcome_formula, exposure_formula) {\n  outcome <- lm(outcome_formula)\n  ps_model <- glm(exposure_formula, family = \"binomial\")\n\n\n  data <- data %>%\n  mutate(ps = predict(ps_model, newdata = data, type = \"response\")) %>%\n  mutate(ipw = case_when(\n            A == 1 ~ 1/ps,\n            A == 0 ~ 1/(1-ps)\n        ))\n\n  example_ipw <- lm(Y ~ A, data = data, weights = ipw)\n\n  forceA0 <- data %>% mutate(A = 0)\n  forceA1 <- data %>% mutate(A = 1)\n\n  predA0 <- predict(outcome, newdata = forceA0)\n  predA1 <- predict(outcome, newdata = forceA1)\n\n  DR1 <-\n    (((    data$A) * data$Y) / (    data$ps)) -      # IPW part\n    ((predA1 * (data$A - data$ps))) / (    data$ps)  # Other thing\n  DR0 <-\n    (((1 - data$A) * data$Y) / (1 - data$ps)) +      # IPW part\n    ((predA0 * (data$A - data$ps))) / (1 - data$ps)  # Other thing\n\n  Estimator1 <- predA1 + ((data$Y * data$A) / (data$ps)) - ((predA1 * data$A) / data$ps)\n  Estimator0 <- predA0 + ((data$Y * (1 - data$A)) / (1 - data$ps)) - ((predA0 * (1 - data$A)) / (1 - data$ps))\n\n\n  part1 <- predA1\n  part2 <- ((data$Y * data$A) / (data$ps))\n  part3 <- -((predA1 * data$A) / data$ps)\n  \n  part1A0 <- predA0\n  part2A0 <- ((data$Y * (1 - data$A)) / (1 - data$ps))\n  part3A0 <- -((predA0 * (1 - data$A)) / (1 - data$ps))\n  \n  partdr1 <- mean(part1) - mean(part1A0)\n  partdr2 <- mean((data$Y * data$A) / (data$ps)) - mean((data$Y * (1 - data$A)) / (1 - data$ps))\n  partdr3 <- mean(-((predA1 * data$A) / data$ps)) - mean(-((predA0 * (1 - data$A)) / (1 - data$ps)))\n\n  mods <- t(c(outcome_formula,exposure_formula))\n  output <- as.data.frame(cbind(mods, outcome$coefficients[2], example_ipw$coefficients[2], partdr1, partdr2, partdr3, sum(partdr1, partdr2, partdr3)))\n  \n  names(output) <- c(\"Outcome Formula\",\"Exposure Formula\", \"Outcome Model Estimate\", \"IPW Estimate\", \"$B$\", \"$C$\", \"D\", \"E\")\n  return(output)\n}"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n \n\n\n\nUntitled\n\n\n\n\n\n\n\n\n\nApr 3, 2023\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nDoubly Robust Estimators\n\n\n\nData Science\n\n\nStatistics\n\n\n\nAn Exploration of a Double Robust Estimator for Causal Inference\n\n\n\n\n\n\nApr 17, 2023\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nBeyond the Report Card: What are the significant predictors?\n\n\n\n\n\n\nThu Dang, Nathaniel Reimer, Jeremy Hubinger\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nBeyond the Report Card: What are the insights at the school level that we can observe?\n\n\n\n\n\n\nThu Dang, Nathaniel Reimer, Jeremy Hubinger\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nBeyond the Report Card: What are the insights at the county level that we can observe?\n\n\n\n\n\n\nThu Dang, Nathaniel Reimer, Jeremy Hubinger\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nBeyond the Report Card: Our Motivation\n\n\n\n\n\n\nThu Dang, Nathaniel Reimer, Jeremy Hubinger\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nBeyond the Report Card: Our Motivation\n\n\n\n\n\n\nThu Dang, Nathaniel Reimer, Jeremy Hubinger\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nBeyond the Report Card: Let’s discuss some results!\n\n\n\n\n\n\nThu Dang, Nathaniel Reimer, Jeremy Hubinger\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nBeyond the Report Card: Investigating the Factors that Define Educational Achievement using California as a Case Study\n\n\n\n\n\n\nThu Dang, Nathaniel Reimer, Jeremy Hubinger\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nBeyond the Report Card: Investigating the Factors that Define Educational Achievement\n\n\n\n\n\n\nThu Dang, Nathaniel Reimer, Jeremy Hubinger\n\n\nInvalid Date\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsteroid Value Analysis\n\n\n\nData Science\n\n\nSpace\n\n\n\nVisualization and Analysis of Asterank data\n\n\n\n\n\n\nDec 14, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  }
]